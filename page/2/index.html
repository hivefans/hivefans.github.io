<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    
    <title>东杰书屋</title>
    
    
        <meta name="keywords" content="东杰书屋" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta property="og:type" content="website">
<meta property="og:title" content="东杰书屋">
<meta property="og:url" content="https://blog.djstudy.net/page/2/index.html">
<meta property="og:site_name" content="东杰书屋">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="东杰书屋">
    

    
        <link rel="alternate" href="/" title="东杰书屋" type="application/atom+xml" />
    

    
        <link rel="icon" href="/favicon.ico" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">
    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?05207dc6d0c785fb39a80bb5af7c3d8a# enter Baidu Analytics hash key";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>

    


    
        <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">东杰书屋</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
                    <a class="main-nav-link" href="/arch">架构</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                    <td><a class="main-nav-link" href="/arch">架构</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            elasticsearch
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/2016/07/27/es-flush-vs-refresh/">elasticsearch中的refresh和flush区别</a></li>  <li class="file"><a href="/2016/02/27/how-many-shards-index/">Optimizing Elasticsearch-How Many Shards per Index</a></li>  <li class="file"><a href="/2017/04/27/es-shard-interaction/">Elasticsearch 分片交互过程详解</a></li>  <li class="file"><a href="/2017/06/06/openresty-kibana-post/">使用openresty获取kibana查询post参数</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            hadoop
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/2016/01/24/hdp-spark-shell-error/">ambari hdp中部署apache spark运行spark shell遇到的错误解决</a></li>  <li class="file"><a href="/2016/07/27/hbase-minor-vs-major-compaction/">hbase 压缩合并中的minor与major区别</a></li>  <li class="file"><a href="/2016/09/28/hbase-rit/">hbase中的RIT的那些事</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            scala
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/2016/03/19/scala-note-2/">scala学习笔记(二)</a></li>  <li class="file"><a href="/2016/03/16/scala-note-1/">scala学习笔记(一)</a></li>  <li class="file"><a href="/2016/01/24/scala-rumen-biji/">scala入门笔记</a></li>  <li class="file"><a href="/2016/07/10/scala-note-3/">scala学习笔记(三)</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            spark
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/2016/01/24/spark-convert-text-parquet/">将 Spark 中的文本转换为 Parquet 以提升性能</a></li>  <li class="file"><a href="/2016/01/24/spark-ha/">Spark Standalone模式HA环境搭建</a></li>  <li class="file"><a href="/2016/01/27/spark-sort-shuffle-analyse/">Spark Sort Based Shuffle内存分析</a></li>  <li class="file"><a href="/2016/01/24/spark-on-yarn/">spark on yarn</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            区块链
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/2018/04/11/qukuailian-note1/">区块链学习笔记（一）</a></li>  </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>tag cloud</span></h3>
        <div class="widget tagcloud">
            <a href="/tags/ambari/" style="font-size: 10px;">ambari</a> <a href="/tags/compaction/" style="font-size: 10px;">compaction</a> <a href="/tags/elasticsearch/" style="font-size: 16.67px;">elasticsearch</a> <a href="/tags/ha/" style="font-size: 10px;">ha</a> <a href="/tags/hbase/" style="font-size: 13.33px;">hbase</a> <a href="/tags/optimizing/" style="font-size: 10px;">optimizing</a> <a href="/tags/parquet/" style="font-size: 10px;">parquet</a> <a href="/tags/rit/" style="font-size: 10px;">rit</a> <a href="/tags/scala/" style="font-size: 16.67px;">scala</a> <a href="/tags/shuffle/" style="font-size: 10px;">shuffle</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/yarn/" style="font-size: 13.33px;">yarn</a> <a href="/tags/区块链/" style="font-size: 10px;">区块链</a> <a href="/tags/比特币/" style="font-size: 10px;">比特币</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title"><span>links</span></h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://macshuo.com/">MacTalk</a>
                    </li>
                
                    <li>
                        <a href="http://slaytanic.blog.51cto.com/">实践检验</a>
                    </li>
                
                    <li>
                        <a href="http://oserror.com/">Charles的技术博客</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main">
        <article id="post-spark-sort-shuffle-analyse" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/shuffle/">shuffle</a>, <a class="tag-link" href="/tags/spark/">spark</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/27/spark-sort-shuffle-analyse/">
            <time datetime="2016-01-27T09:51:18.000Z" itemprop="datePublished">2016-01-27</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/spark-sort-shuffle-analyse.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/spark-sort-shuffle-analyse.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/spark-sort-shuffle-analyse.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/27/spark-sort-shuffle-analyse/">Spark Sort Based Shuffle内存分析</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                
                    
                    <p><h2 id="u524D_u8A00"><a href="#u524D_u8A00" class="headerlink" title="前言"></a>前言</h2><p>借用和董神的一段对话说下背景：</p>
<p>shuffle共有三种，别人讨论的是hash shuffle，这是最原始的实现，曾经有两个版本，第一版是每个map产生r个文件，一共产生mr个文件，由于产生的中间文件太大影响扩展性，社区提出了第二个优化版本，让一个core上map共用文件，减少文件数目，这样共产生corer个文件，好多了，但中间文件数目仍随任务数线性增加，仍难以应对大作业，但hash shuffle已经优化到头了。为了解决hash shuffle性能差的问题，又引入sort shuffle，完全借鉴mapreduce实现，每个map产生一个文件，彻底解决了扩展性问题<br>目前Sort Based Shuffle 是作为默认Shuffle类型的。Shuffle 是一个很复杂的过程，任何一个环节都足够写一篇文章。所以这里，我尝试换个方式，从实用的角度出发，让读者有两方面的收获：</p>
<p>剖析哪些环节，哪些代码可能会让内存产生问题<br>控制相关内存的参数<br>有时候，我们宁可程序慢点，也不要OOM，至少要先跑步起来，希望这篇文章能够让你达成这个目标。</p>
<p>同时我们会提及一些类名，这些类方便你自己想更深入了解时，可以方便的找到他们，自己去探个究竟。</p>
<h2 id="Shuffle__u6982_u89C8"><a href="#Shuffle__u6982_u89C8" class="headerlink" title="Shuffle 概览"></a>Shuffle 概览</h2><p>Spark 的Shuffle 分为 Write,Read 两阶段。我们预先建立三个概念：</p>
<p>
                
            
        
        
            </div>   
            <div class="article-more-link">
                <a href="/2016/01/27/spark-sort-shuffle-analyse/#more">Read More</a>
            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <article id="post-scala-rumen-biji" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/scala/">scala</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/scala/">scala</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/24/scala-rumen-biji/">
            <time datetime="2016-01-24T11:09:23.000Z" itemprop="datePublished">2016-01-24</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/scala-rumen-biji.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/scala-rumen-biji.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/scala-rumen-biji.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/24/scala-rumen-biji/">scala入门笔记</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                
                    
                    <p><h3 id="Scala_u7B80_u4ECB"><a href="#Scala_u7B80_u4ECB" class="headerlink" title="Scala简介"></a>Scala简介</h3><p>Scala 是一门多范式的编程语言, 由Martin Odersky 于2001年基于Funnel的工作开始设计Scala并于2004年正式发布<br>Scala是一种纯面向对象的语言，每个值都是对象<br>Scala是一门多范式编程语言, 支持命令交互式, 函数式, 面向对象<br>编译型高性能语言(静态)<br>与Java无缝兼容, 可以使用任何Java库</p>
<h3 id="u4EE3_u7801_u98CE_u683C"><a href="#u4EE3_u7801_u98CE_u683C" class="headerlink" title="代码风格"></a>代码风格</h3><ol>
<li>函数和变量以小驼峰命名</li>
<li>类和特质以大驼峰命名</li>
<li>常量使用全大写命名</li>
<p>
                
            
        
        
            </div>   
            <div class="article-more-link">
                <a href="/2016/01/24/scala-rumen-biji/#more">Read More</a>
            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <article id="post-spark-convert-text-parquet" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/parquet/">parquet</a>, <a class="tag-link" href="/tags/spark/">spark</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/24/spark-convert-text-parquet/">
            <time datetime="2016-01-24T10:46:44.000Z" itemprop="datePublished">2016-01-24</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/spark-convert-text-parquet.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/spark-convert-text-parquet.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/spark-convert-text-parquet.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/24/spark-convert-text-parquet/">将 Spark 中的文本转换为 Parquet 以提升性能</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                
                    
                    <p><p>列式存储布局（比如 Parquet）可以加速查询，因为它只检查所有需要的列并对它们的值执行计算，因此只读取一个数据文件或表的小部分数据。Parquet 还支持灵活的压缩选项，因此可以显著减少磁盘上的存储。<br>如果您在 HDFS 上拥有基于文本的数据文件或表，而且正在使用 Spark SQL 对它们执行查询，那么强烈推荐将文本数据文件转换为 Parquet 数据文件，以实现性能和存储收益。当然，转换需要时间，但查询性能的提升在某些情况下可能达到 30 倍或更高，存储的节省可高达 75%！<br>已有文章介绍使用 Parquet 存储为 BigSQL、Hive 和 Impala 带来类似的性能收益，本文将介绍如何编写一个简单的 Scala 应用程序，将现有的基于文本的数据文件或表转换为 Parquet 数据文件，还将展示给 Spark SQL 带来的实际存储节省和查询性能提升。</p>
<h3 id="u8BA9_u6211_u4EEC_u8F6C_u6362_u4E3A_Parquet__u5427_uFF01"><a href="#u8BA9_u6211_u4EEC_u8F6C_u6362_u4E3A_Parquet__u5427_uFF01" class="headerlink" title="让我们转换为 Parquet 吧！"></a>让我们转换为 Parquet 吧！</h3><p>Spark SQL 提供了对读取和写入 Parquet 文件的支持，能够自动保留原始数据的模式。Parquet 模式通过 Data Frame API，使数据文件对 Spark SQL 应用程序 “不言自明”。当然，Spark SQL 还支持读取已存储为 Parquet 的现有 Hive 表，但您需要配置 Spark，以便使用 Hive 的元存储来加载所有信息。在我们的示例中，不涉及 Hive 元存储。<br>以下 Scala 代码示例将读取一个基于文本的 CSV 表，并将它写入 Parquet 表：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span></span>(sqlContext: <span class="type">SQLContext</span>, filename: <span class="type">String</span>, schema: <span class="type">StructType</span>, tablename: <span class="type">String</span>) &#123;</div><div class="line">     <span class="comment">// import text-based table first into a data frame</span></div><div class="line">     <span class="keyword">val</span> df = sqlContext.read.format(<span class="string">"com.databricks.spark.csv"</span>).</div><div class="line">       schema(schema).option(<span class="string">"delimiter"</span>, <span class="string">"|"</span>).load(filename)</div><div class="line">     <span class="comment">// now simply write to a parquet file</span></div><div class="line">     df.write.parquet(<span class="string">"/user/spark/data/parquet/"</span>+tablename)</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> <span class="comment">// usage exampe -- a tpc-ds table called catalog_page</span></div><div class="line"> schema= <span class="type">StructType</span>(<span class="type">Array</span>(</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_sk"</span>,        <span class="type">IntegerType</span>,<span class="literal">false</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_id"</span>,        <span class="type">StringType</span>,<span class="literal">false</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_start_date_sk"</span>,          <span class="type">IntegerType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_end_date_sk"</span>,            <span class="type">IntegerType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_department"</span>,             <span class="type">StringType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_number"</span>,         <span class="type">LongType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_number"</span>,    <span class="type">LongType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_description"</span>,            <span class="type">StringType</span>,<span class="literal">true</span>),</div><div class="line">         <span class="type">StructField</span>(<span class="string">"cp_type"</span>,                   <span class="type">StringType</span>,<span class="literal">true</span>)))</div><div class="line"> convert(sqlContext,</div><div class="line">         hadoopdsPath+<span class="string">"/catalog_page/*"</span>,</div><div class="line">         schema,</div><div class="line">         <span class="string">"catalog_page"</span>)</div></pre></td></tr></table></figure></p>
<p>上面的代码将会读取 hadoopdsPath+”/catalog_page/* 中基于文本的 CSV 文件，并将转换的 Parquet 文件保存在 /user/spark/data/parquet/ 下。此外，转换的 Parquet 文件会在 gzip 中自动压缩，因为 Spark 变量 spark.sql.parquet.compression.codec 已在默认情况下设置为 gzip。您还可以将压缩编解码器设置为 uncompressed、snappy 或 lzo。</p>
<h3 id="u8F6C_u6362_1_TB__u6570_u636E_u5C06_u82B1_u8D39_u591A_u957F_u65F6_u95F4_uFF1F"><a href="#u8F6C_u6362_1_TB__u6570_u636E_u5C06_u82B1_u8D39_u591A_u957F_u65F6_u95F4_uFF1F" class="headerlink" title="转换 1 TB 数据将花费多长时间？"></a>转换 1 TB 数据将花费多长时间？</h3><p>50 分钟，在一个 6 数据节点的 Spark v1.5.1 集群上可达到约 20 GB/分的吞吐量。使用的总内存约为 500GB。HDFS 上最终的 Parquet 文件的格式为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/user/spark/data/parquet/catalog_page/part-r-00000-9ff58e65-0674-440a-883d-256370f33c66.gz.parquet</div><div class="line">/user/spark/data/parquet/catalog_page/part-r-00001-9ff58e65-0674-440a-883d-256370f33c66.gz.parquet</div></pre></td></tr></table></figure></p>
<h3 id="u5B58_u50A8_u8282_u7701"><a href="#u5B58_u50A8_u8282_u7701" class="headerlink" title="存储节省"></a>存储节省</h3><p>以下 Linux 输出显示了 TEXT 和 PARQUET 在 HDFS 上的大小比较：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ hadoop fs -du -h -s /user/spark/hadoopds1000g</div><div class="line">    897.9 G  /user/spark/hadoopds1000g</div><div class="line">    % hadoop fs -du -h -s /user/spark/data/parquet</div><div class="line">    231.4 G  /user/spark/data/parquet</div></pre></td></tr></table></figure></p>
<p>
                
            
        
        
            </div>   
            <div class="article-more-link">
                <a href="/2016/01/24/spark-convert-text-parquet/#more">Read More</a>
            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <article id="post-spark-ha" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/ha/">ha</a>, <a class="tag-link" href="/tags/spark/">spark</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/24/spark-ha/">
            <time datetime="2016-01-24T08:10:30.000Z" itemprop="datePublished">2016-01-24</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/spark-ha.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/spark-ha.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/spark-ha.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/24/spark-ha/">Spark Standalone模式HA环境搭建</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
            
        
        
            <p>Spark Standalone模式常见的HA部署方式有两种：基于文件系统的HA和基于ZK的HA<br>本篇只介绍基于ZK的HA环境搭建：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ SPARK_HOME/conf/spark-env.sh</div></pre></td></tr></table></figure></p>
<p>添加SPARK_DAEMON_JAVA_OPTS的配置信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop000:2181,hadoop001:2181,hadoop002:2181 -Dspark.deploy.zookeeper.dir=/spark"</span></div></pre></td></tr></table></figure></p>
<h3 id="u914D_u7F6E_u53C2_u6570_u8BF4_u660E_uFF1A"><a href="#u914D_u7F6E_u53C2_u6570_u8BF4_u660E_uFF1A" class="headerlink" title="配置参数说明："></a>配置参数说明：</h3><p>spark.deploy.recoveryMode: 设置恢复模式为zk，默认为NONE<br>spark.deploy.zookeeper.url: 设置ZK集群的url，形如：192.168.1.100:2181,192.168.1.101:2181<br>spark.deploy.zookeeper.dir: 设置zk保存恢复状态的路径，默认为spark<br>实现HA的原理：利用ZK的Leader Election机制，选择一个Active状态的Master，其余的Master均为Standby状态；当Active状态的Master死掉后，通过ZK选举一个Standby状态的Master为Active状态。</p>
<h3 id="u6D4B_u8BD5_u6B65_u9AA4_uFF1A"><a href="#u6D4B_u8BD5_u6B65_u9AA4_uFF1A" class="headerlink" title="测试步骤："></a>测试步骤：</h3><p>启动standalone集群后，在各个Standby节点上启动start-master.sh，jps观察是否已经正确启动Master进程；<br>将Active状态的Master kill掉，观察8080端口对应的页面，发现已经从Standby状态中选举出一个当作Active状态。<br>采用ZK后由于会有多个Master，在提交任务时不知道哪个为Active状态的Master，可以采用如下的方式提交：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">spark-shell –master spark://hadoop000:7077,hadoop001:7077,hadoop002:7077 –executor-memory 2g –total-executor-cores 1</div><div class="line">详细信息参见官方文档：http://spark.apache.org/docs/latest/spark-standalone.html<span class="comment">#standby-masters-with-zookeeper</span></div></pre></td></tr></table></figure></p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <article id="post-spark-on-yarn" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/spark/">spark</a>, <a class="tag-link" href="/tags/yarn/">yarn</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/24/spark-on-yarn/">
            <time datetime="2016-01-24T06:43:59.000Z" itemprop="datePublished">2016-01-24</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/spark-on-yarn.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/spark-on-yarn.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/spark-on-yarn.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/24/spark-on-yarn/">spark on yarn</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                    
                    
                
                
                    
                    <p><h2 id="u4E3A_u4EC0_u4E48_u8981_u4F7F_u7528YARN_3F"><a href="#u4E3A_u4EC0_u4E48_u8981_u4F7F_u7528YARN_3F" class="headerlink" title="为什么要使用YARN?"></a>为什么要使用YARN?</h2><p>数据共享、资源利用率、更方便的管理集群等。<br>详情参见：<a href="http://www.cnblogs.com/luogankun/p/3887019.html" target="_blank" rel="external">http://www.cnblogs.com/luogankun/p/3887019.html</a></p>
<h2 id="Spark_YARN_u7248_u672C_u7F16_u8BD1"><a href="#Spark_YARN_u7248_u672C_u7F16_u8BD1" class="headerlink" title="Spark YARN版本编译"></a>Spark YARN版本编译</h2><p>编译hadoop对应的支持YARN的Spark版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">export</span> MAVEN_OPTS=<span class="string">"-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"</span></div><div class="line">$ mvn clean package -DskipTests -Phadoop-2.3 -Dhadoop.version=2.3.0-cdh5.0.0 -Dprotobuf.version=2.5.0 -Pyarn -Phive</div></pre></td></tr></table></figure></p>
<p>详情参见：<a href="http://www.cnblogs.com/luogankun/p/3798403.html" target="_blank" rel="external">Spark On YARN</a></p>
<p>Spark的Cluster Manager负责管理启动executor进程，集群可以是Standalone、YARN和Mesos<br>每个SparkContext（换句话说是：Application）对应一个ApplicationMaster（Application启动过程中的第一个容器<br>ApplicationMaster负责和ResourceManager打交道，并请求资源，当获取资源之后通知NodeManager为其启动container； 每个Container中运行一个ExecutorBackend<br>ResourceManager决定哪些Application可以运行、什么时候运行以及在哪些NodeManager上运行； NodeManager的Container上运行executor进程<br>在Standalone模式中有Worker的概念，而在Spark On YARN中没有Worker的概念<br>由于executor是运行在container中，故container内存要大于executor的内存<br>Spark On YARN有两种：</p>
<h3 id="yarn-client"><a href="#yarn-client" class="headerlink" title="yarn-client"></a>yarn-client</h3><p>Client和Driver运行在一起，ApplicationMaster只负责获取资源<br>　　Client会和请求到的资源container通信来调度他们进行工作，也就是说Client不能退出滴；<br>　　日志信息输出能输出在终端控制台上，适用于交互或者调试，也就是希望快速地看到application的输出，比如SparkStreaming<br><img src="/images/yarn-client.png" alt="yarn-client" title="yarn client"></p>
<p>
                
            
        
        
            </div>   
            <div class="article-more-link">
                <a href="/2016/01/24/spark-on-yarn/#more">Read More</a>
            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <article id="post-hdp-spark-shell-error" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/ambari/">ambari</a>, <a class="tag-link" href="/tags/spark/">spark</a>, <a class="tag-link" href="/tags/yarn/">yarn</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2016/01/24/hdp-spark-shell-error/">
            <time datetime="2016-01-24T05:05:21.000Z" itemprop="datePublished">2016-01-24</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/raw/master/source/_posts/hdp-spark-shell-error.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/_edit/master/source/_posts/hdp-spark-shell-error.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='http://git.djstudy.net/hivefans/blog/commits/master/source/_posts/hdp-spark-shell-error.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2016/01/24/hdp-spark-shell-error/">ambari hdp中部署apache spark运行spark shell遇到的错误解决</a>
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                
                
                    
                    
                
                    
                    
                
                    
                    
                
            
        
        
            <p>在运行spark-shell中遇到的ERROR lzo.GPLNativeCodeLoader: Could not load native gpl library 解决方法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/spark-shell –driver-library-path :/usr/hdp/2.2.4.2-2/hadoop/lib/native/Linux-amd64-64 /usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar</div></pre></td></tr></table></figure></p>
<p>在运行spark-shell中遇到的Compression codec com.hadoop.compression.lzo.LzoCodec not found 错误可以配置文件spark-defaults.conf<br>spark.executor.extraClassPath /usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar<br>spark.driver.extraClassPath /usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar<br>保存文件重启spark服务集群即可。<br>再提供一个Unable to load native-hadoop library 和 Snappy native library not loaded的解决方案。这个问题主要是jre目录下缺少了libgplcompression.so , libhadoop.so和libsnappy.so两个文件。具体是，spark-shell依赖的是scala，scala依赖的是JAVA_HOME下的jdk，libhadoop.so和libsnappy.so两个文件应该放到JAVA_HOME/jre/lib/amd64下面。要注意的是要知道真正依赖到的JAVA_HOME是哪一个，把两个.so放对地方。这两个so：libhadoop.so和libsnappy.so。前一个so可以在HADOOP_HOME下找到，比如hadoop\lib\native\Linux-amd64-64。第二个libsnappy.so需要下载一个snappy-1.1.0.tar.gz，然后./configure，make编译出来。snappy是google的一个压缩算法，在hadoop jira下<a href="https://issues.apache.org/jira/browse/HADOOP-7206记录了这次集成。" target="_blank" rel="external">https://issues.apache.org/jira/browse/HADOOP-7206记录了这次集成。</a></p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>






    
        <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
        </nav>
    
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            东杰 &copy; 2018 
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        
    
    <script type="text/javascript">
    var duoshuoQuery = {short_name:'hivefans'};
    (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
    || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
    </script>



    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>