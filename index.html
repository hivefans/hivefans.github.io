<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="东杰书屋" type="application/atom+xml" />






<meta property="og:type" content="website">
<meta property="og:title" content="东杰书屋">
<meta property="og:url" content="https://blog.djstudy.net/index.html">
<meta property="og:site_name" content="东杰书屋">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="东杰书屋">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://blog.djstudy.net/"/>





  <title>东杰书屋</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">东杰书屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">环境不会改变，解决之道在于改变自己。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech">
          <a href="/tech/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            tech
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2018/04/19/hbase-module/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/19/hbase-module/" itemprop="url">hbase中核心组件与作用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-19T10:23:05+08:00">
                2018-04-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>HBase中的组件包括Client、Zookeeper、HMaster、HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog等。</p>
<p>1.Client的作用</p>
<blockquote>
<p>1.1 包含访问HBase的接口，并维护cache来加快对HBase的访问，比如region的位置信息<br>1.2 HBase Client通过RPC方式和HMaster、HRegionServer通信</p>
</blockquote>
<p>2.Zookeeper的作用</p>
<blockquote>
<p>2.1 实现HMaster主从节点的failover,集群高可用;<br>2.2 存储所有Region的寻址入口;<br>2.3 实时监控Region server的上线和下线信息。并实时通知给master;<br>2.4 存储HBase的schema和table元数据;<br>2.5 通过选举，保证任何时候，集群中只有一个master，Master与RegionServers 启动时会向ZooKeeper注册。</p>
</blockquote>
<p>3.HMaster的作用</p>
<blockquote>
<p>3.1 为HRegionServer分配region；<br>3.2 管理HRegionServer实现其负载均衡；<br>3.3 发现失效的Region server并重新分配其上的region；<br>3.4 HDFS上的垃圾文件回收；<br>3.5 实现DDL操作，处理schema更新请求。</p>
</blockquote>
<p><code>从Hmaster功能可以看出，如果Hmaster挂掉，并不影响数据的读写，而会导致元数据无法修改，以及region的分配工作。</code></p>
<p>4.HRegionServer的作用</p>
<blockquote>
<p>4.1 存放和管理本地HRegion，并负责切分正在运行过程中变的过大的region；<br>4.2 维护master分配给他的region，处理对这些region的io请求。</p>
</blockquote>
<p><code>（ps:client访问hbase上的数据时不需要master的参与，因为数据寻址访问zookeeper和region server，
而数据读写访问region server。master仅仅维护table和region的元数据信息，而table的元数据信息
保存在zookeeper上，因此master负载很低。)</code></p>
<p>5.HRegion的作用</p>
<blockquote>
<p>5.1 Region是HBase中分布式存储和负载均衡的最小单元；<br>5.2 不同的region可以分别在不同的Region Server上；<br>5.3 Region按大小分隔，每个表一般是只有一个region，当region的某个列族达到一个阈值（默认256M）<br>时就会分成两个新的region；<br>5.4 Region被分配给哪个Region Server是完全动态透明的。</p>
</blockquote>
<p>6.Store的作用</p>
<blockquote>
<p>6.1 每一个region由一个或多个store组成，至少是一个store；<br>6.2 hbase会把一起访问的数据放在一个store里面，即为每个 ColumnFamily建一个store，<br>如果有几个ColumnFamily，也就有几个Store；<br>6.3 一个Store由一个memStore和0或者多个StoreFile组成，HBase以store的大小来判断是否需要切分region。</p>
</blockquote>
<p>7.MemStore的作用</p>
<blockquote>
<p>7.1 memStore 是放在内存里的，其保存修改的数据即keyValues；<br>7.2 当memStore的大小达到一个阀值（默认64MB）时，memStore会被flush到文 件，即生成一个快照。</p>
</blockquote>
<p>8.StoreFile的作用</p>
<blockquote>
<p>8.1 memStore内存中的数据写到文件后就是StoreFile;<br>8.2 StoreFile底层是以HFile的格式保存,即数据保存在hdfs上。</p>
</blockquote>
<p>9.HLog的作用</p>
<blockquote>
<p>9.1 HLog(WAL log)：WAL意为write ahead log，用来做灾难恢复使用，HLog记录数据的所有变更，一旦region server 宕机，就可以从log中进行恢复；<br>9.2 HLog文件就是一个普通的Hadoop Sequence File，Sequence File的value是key时HLogKey对象，其中记录了写入数据的归属信息，除了table和region名字外，还同时包括sequence number和timestamp<br>timestamp是写入时间，sequence number的起始值为0，或者是最近一次存入文件系统中的sequence number。<br>Sequence File的value是HBase的KeyValue对象，即对应HFile中的KeyValue。</p>
</blockquote>
<p>转自： <a href="https://my.oschina.net/u/2000675/blog/663852" target="_blank" rel="noopener">https://my.oschina.net/u/2000675/blog/663852</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2018/04/11/qukuailian-note1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/11/qukuailian-note1/" itemprop="url">区块链学习笔记（一）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-11T10:23:11+08:00">
                2018-04-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/区块链/" itemprop="url" rel="index">
                    <span itemprop="name">区块链</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u533A_u5757_u94FE_u672C_u8D28"><a href="#u533A_u5757_u94FE_u672C_u8D28" class="headerlink" title="区块链本质"></a>区块链本质</h2><p>它是一种特殊的分布式数据库。</p>
<h2 id="u533A_u5757_u94FE_u7279_u5F81"><a href="#u533A_u5757_u94FE_u7279_u5F81" class="headerlink" title="区块链特征"></a>区块链特征</h2><ol>
<li>分布式去中心化</li>
<li>无须信任系统</li>
<li>集体维护</li>
<li>可靠数据库</li>
<li>匿名性</li>
<li>开源</li>
</ol>
<h2 id="u533A_u5757_u94FE_u7ED3_u6784"><a href="#u533A_u5757_u94FE_u7ED3_u6784" class="headerlink" title="区块链结构"></a>区块链结构</h2><p>区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。<br>每个区块包含两个部分。</p>
<p><code>区块头（Head）：记录当前区块的特征值
区块体（Body）：实际数据</code></p>
<p>区块头包含了当前区块的多项特征值</p>
<p><code>生成时间
实际数据（即区块体）的哈希
上一个区块的哈希</code><br><img src="/images/15234270837536.png" alt="区块链结构"></p>
<h2 id="u533A_u5757_u94FE_u7684_u5206_u53C9"><a href="#u533A_u5757_u94FE_u7684_u5206_u53C9" class="headerlink" title="区块链的分叉"></a>区块链的分叉</h2><p>为什么区块链会发生分叉呢？原因就在于去中心化。</p>
<ol>
<li><p>网速的延迟</p>
</li>
<li><p>双重交易</p>
</li>
</ol>
<p>现在的规则是，新节点总是采用最长的那条区块链。如果区块链有分叉，将看哪个分支在分叉点后面，先达到6个新区块（称为”六次确认”）。按照10分钟一个区块计算，一小时就可以确认。<br><img src="/images/15234283648590.jpg" alt="区块链分叉"></p>
<h2 id="u5E94_u7528_u573A_u666F"><a href="#u5E94_u7528_u573A_u666F" class="headerlink" title="应用场景"></a>应用场景</h2><p>为了保证数据的可靠性，区块链也有自己的代价。一是效率，数据写入区块链，最少要等待十分钟，所有节点都同步数据，则需要更多的时间；二是能耗，区块的生成需要矿工进行无数无意义的计算，这是非常耗费能源的。</p>
<p>因此，区块链的适用场景，其实非常有限。</p>
<p><code>不存在所有成员都信任的管理当局
写入的数据不要求实时使用
挖矿的收益能够弥补本身的成本</code></p>
<p>如果无法满足上述的条件，那么传统的数据库是更好的解决方案。目前，区块链最大的应用场景（可能也是唯一的应用场景），就是以比特币为代表的加密货币。</p>
<h2 id="u53C2_u8003_u94FE_u63A5"><a href="#u53C2_u8003_u94FE_u63A5" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html</a><br><a href="https://mp.weixin.qq.com/s/JEkjYdvRw2x3PzxKDR7FQQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/JEkjYdvRw2x3PzxKDR7FQQ</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2017/06/06/openresty-kibana-post/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/06/openresty-kibana-post/" itemprop="url">使用openresty获取kibana查询post参数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-06T10:23:11+08:00">
                2017-06-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="openresty_u914D_u7F6E_u653E_u5230_u5305_u542Bfastcgi_pass_u6216proxy_pass_u7684Location_u91CC_u9762"><a href="#openresty_u914D_u7F6E_u653E_u5230_u5305_u542Bfastcgi_pass_u6216proxy_pass_u7684Location_u91CC_u9762" class="headerlink" title="openresty配置放到包含fastcgi_pass或proxy_pass的Location里面"></a>openresty配置放到包含fastcgi_pass或proxy_pass的Location里面</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">log_format  main  &apos;$remote_addr | [$time_iso8601] | &quot;$request&quot; | &apos; &apos;$status | $body_bytes_sent | &quot;$http_referer&quot;  | &apos; &apos;&quot;$http_user_agent&quot; | &quot;$http_x_forwarded_for&quot; |  &quot;$request_body&quot;&apos;;</span><br><span class="line">server &#123;</span><br><span class="line">             listen       80;</span><br><span class="line">             server_name  esclient.test.net;</span><br><span class="line">             location / &#123;</span><br><span class="line">                proxy_pass http://192.168.1.47:5601;</span><br><span class="line">                proxy_http_version 1.1;</span><br><span class="line">                proxy_set_header Connection &quot;&quot;;</span><br><span class="line">                proxy_connect_timeout 5s;</span><br><span class="line">                proxy_read_timeout 10s;</span><br><span class="line">                access_log /usr/local/openresty/nginx/logs/kibana.access.log main;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h3 id="u653E_u5230_u4EFB_u610FLocation_u91CC_u9762"><a href="#u653E_u5230_u4EFB_u610FLocation_u91CC_u9762" class="headerlink" title="放到任意Location里面"></a>放到任意Location里面</h3><p>Location里面加上如下语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lua_need_request_body on;  </span><br><span class="line">content_by_lua &apos;local s = ngx.var.request_body&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="nginx__u76F4_u63A5_u5728_u914D_u7F6E_u6587_u7AE0_u4E2D_u8BBE_u7F6E_u65E5_u5FD7_u5206_u5272"><a href="#nginx__u76F4_u63A5_u5728_u914D_u7F6E_u6587_u7AE0_u4E2D_u8BBE_u7F6E_u65E5_u5FD7_u5206_u5272" class="headerlink" title="nginx 直接在配置文章中设置日志分割"></a>nginx 直接在配置文章中设置日志分割</h3><p>直接在nginx配置文件中，配置日志循环，而不需使用logrotate或配置cron任务。需要使用到$time_iso8601 内嵌变量来获取时间。$time_iso8601格式如下：2015-08-07T18:12:02+02:00。然后使用正则表达式来获取所需时间的数据。<br>按天分割日志</p>
<p>使用下面的代码块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)&quot;) &#123;</span><br><span class="line">    set $year $1;</span><br><span class="line">    set $month $2;</span><br><span class="line">    set $day $3;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">access_log /data/logs/nginx/www.ttlsa.com-$year-$month-$day-access.log;</span><br></pre></td></tr></table></figure></p>
<p>也可以使用Perl语法来捕获，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(?&lt;year&gt;\d&#123;4&#125;)-(?&lt;month&gt;\d&#123;2&#125;)-(?&lt;day&gt;\d&#123;2&#125;)&quot;) &#123;&#125;</span><br><span class="line">access_log /data/logs/nginx/www.ttlsa.com-$year-$month-$day-access.log;</span><br></pre></td></tr></table></figure></p>
<p>按时、分、秒分割<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if ($time_iso8601 ~ &quot;^(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)T(\d&#123;2&#125;):(\d&#123;2&#125;):(\d&#123;2&#125;)&quot;)</span><br><span class="line">&#123;</span><br><span class="line">    set $year $1;</span><br><span class="line">    set $month $2;</span><br><span class="line">    set $day $3;</span><br><span class="line">    set $hour $4;</span><br><span class="line">    set $minutes $5;</span><br><span class="line">    set $seconds $6;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2017/04/27/es-shard-interaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/04/27/es-shard-interaction/" itemprop="url">Elasticsearch 分片交互过程详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-27T13:03:47+08:00">
                2017-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="u4E00_u3001Elasticseach_u5982_u4F55_u5C06_u6570_u636E_u5B58_u50A8_u5230_u5206_u7247_u4E2D"><a href="#u4E00_u3001Elasticseach_u5982_u4F55_u5C06_u6570_u636E_u5B58_u50A8_u5230_u5206_u7247_u4E2D" class="headerlink" title="一、Elasticseach如何将数据存储到分片中"></a>一、Elasticseach如何将数据存储到分片中</h3><p>问题：当我们要在ES中存储数据的时候，数据应该存储在主分片和复制分片中的哪一个中去；当我们在ES中检索数据的时候，又是怎么判断要查询的数据是属于哪一个分片。</p>
<p>数据存储到分片的过程是一定规则的，并不是随机发生的。</p>
<p>规则：shard = hash(routing) % number_of_primary_shards</p>
<p>Routing值可以是一个任意的字符串，默认情况下，它的值为存数数据对应文档 _id 值，也可以是用户自定义的值。Routing这个字符串通过一个hash的函数处理，并返回一个数值，然后再除以索引中主分片的数目，所得的余数作为主分片的编号，取值一般在0到number_of_primary_shards - 1的这个范围中。通过这种方法计算出该数据是存储到哪个分片中。</p>
<p>正是这种路由机制，导致了主分片的个数为什么在索引建立之后不能修改。对已有索引主分片数目的修改直接会导致路由规则出现严重问题，部分数据将无法被检索。</p>
<h3 id="u4E8C_u3001_u4E3B_u5206_u7247_u4E0E_u590D_u5236_u5206_u7247_u5982_u4F55_u4EA4_u4E92"><a href="#u4E8C_u3001_u4E3B_u5206_u7247_u4E0E_u590D_u5236_u5206_u7247_u5982_u4F55_u4EA4_u4E92" class="headerlink" title="二、主分片与复制分片如何交互"></a>二、主分片与复制分片如何交互</h3><p>为了说明这个问题，我用一个例子来说明。<br><img src="/images/es-shard-interaction1.png" alt="elasticsearch"><br>在上面这个例子中，有三个ES的node，其中每一个index中包含两个primary shard，每个primary shard拥有一个replica shard。下面从几种常见的数据操作来说明二者之间的交互情况。</p>
<p>1、索引与删除一个文档<br><img src="/images/es-shard-interaction2.png" alt="elasticsearch"></p>
<p>这两种过程均可以分为三个过程来描述：<br>阶段1：客户端发送了一个索引或者删除的请求给node 1。</p>
<p>阶段2：node 1通过请求中文档的 _id 值判断出该文档应该被存储在shard 0 这个分片中，并且node 1知道shard 0的primary shard位于node 3这个节点上。因此node 1会把这个请求转发到node 3。</p>
<p>阶段3：node 3在shard 0 的primary shard上执行请求。如果请求执行成功，它node 3将并行地将该请求发给shard 0的其余所有replica shard上，也就是存在于node 1和node 2中的replica shard。如果所有的replica shard都成功地执行了请求，那么将会向node 3回复一个成功确认，当node 3收到了所有replica shard的确认信息后，则最后向用户返回一个Success的消息。</p>
<p>2、更新一个文档<br><img src="/images/es-shard-interaction3.png" alt="elasticsearch"><br>该过程可以分为四个阶段来描述：<br>阶段1：客户端向node 1发送一个文档更新的请求。</p>
<p>阶段2：同样的node 1通过请求中文档的 _id 值判断出该文档应该被存储在shard 0 这个分片中，并且node 1知道shard 0的primary shard位于node 3这个节点上。因此node 1会把这个请求转发到node 3。</p>
<p>阶段3：node 3从文档所在的primary shard中获取到它的JSON文件，并修改其中的_source中的内容，之后再重新索引该文档到其primary shard中。</p>
<p>阶段4：如果node 3成功地更新了文档，node 3将会把文档新的版本并行地发给其余所有的replica shard所在node中。这些node也同样重新索引新版本的文档，执行后则向node 3确认成功，当node 3接收到所有的成功确认之后，再向客户端发送一个更新成功的信息。</p>
<p>3、检索文档<br>CRUD这些操作的过程中一般都是结合一些唯一的标记例如：_index，_type，以及routing的值，这就意味在执行操作的时候都是确切的知道文档在集群中的哪个node中，哪个shard中。</p>
<p>而检索过程往往需要更多的执行模式，因为我们并不清楚所要检索的文档具体位置所在， 它们可能存在于ES集群中个任何位置。因此，一般情况下，检索的执行不得不去询问index中的每一个shard。</p>
<p>但是，找到所有匹配检索的文档仅仅只是检索过程的一半，在向客户端返回一个结果列表之前，必须将各个shard发回的小片的检索结果，拼接成一个大的已排好序的汇总结果列表。正因为这个原因，检索的过程将分为查询阶段与获取阶段（Query Phase and Fetch Phase）。</p>
<p>Query Phase<br>在最初的查询过程中，查询请求会广播到index中的每一个primary shard和replica shard中，每一个shard会在本地执行检索，并建立一个优先级队列（priority queue）。这个优先级队列是一个根据文档匹配度这个指标所排序列表，列表的长度由分页参数from和size两个参数所决定。例如：<br><img src="/images/es-shard-interaction4.png" alt="elasticsearch"></p>
<p>下面从一个例子中说明这个过程：</p>
<p><img src="/images/es-shard-interaction5.png" alt="elasticsearch"><br>Query Phase阶段可以再细分成3个小的子阶段：</p>
<p>子阶段1：客户端发送一个检索的请求给node 3，此时node 3会创建一个空的优先级队列并且配置好分页参数from与size。</p>
<p>子阶段2：node 3将检索请求发送给该index中个每一个shard（这里的每一个意思是无论它是primary还是replica，它们的组合可以构成一个完整的index数据）。每个shard在本地执行检索，并将结果添加到本地优先级队列中。</p>
<p>子阶段3：每个shard返回本地优先级序列中所记录的_id与sort值，并发送node 3。Node 3将这些值合并到自己的本地的优先级队列中，并做全局的排序。</p>
<p>Fetch Phase<br>Query Phase主要定位了所要检索数据的具体位置，但是我们还必须取回它们才能完成整个检索过程。而Fetch Phase阶段的任务就是将这些定位好的数据内容取回并返回给客户端。</p>
<p>同样也用一个例子来说明这个过程：<br><img src="/images/es-shard-interaction6.png" alt="elasticsearch"></p>
<p>Fetch Phase过程可以分为三个子过程来描述：</p>
<p>子阶段1：node 3获取了所有待检索数据的定位之后，发送一个mget的请求给与数据相关的shard。</p>
<p>子阶段2：每个收到node 3的get请求的shard将读取相关文档_source中的内容，并将它们返回给node 3。</p>
<p>子阶段3：当node 3获取到了所有shard返回的文档后，node 3将它们合并成一条汇总的结果，返回给客户端。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/09/28/hbase-rit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/09/28/hbase-rit/" itemprop="url">hbase中的RIT的那些事</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-09-28T11:53:10+08:00">
                2016-09-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>相信长时间运维HBase集群的童鞋肯定都会对RIT（Region-In-Transition，很多参考资料误解为Region-In-Transaction，需要注意）有一种咬牙切齿的痛恨感，一旦Region处于长时间的RIT就会有些不知所措，至少以前的我就是这样过来的。正所谓“恐惧来源于未知”，不知所措意味着我们对RIT知之甚少，然而“凡事都有因果，万事皆有源头”，处于RIT状态的Region只是肉眼看到的一个结果，为什么会处于RIT状态才是问题探索的根本，也是解决问题的关键。本文就基于hbase 0.98.9版本对RIT的工作机制以及实现原理进行普及性的介绍，同时在此基础上通过真实案例讲解如何正确合理地处理处于RIT状态的Region。一方面希望大家能够更好的了解RIT机制，另一方面希望通过本文的学习之后可以不再’惧怕’RIT，正确认识处于RIT状态的Region。</p>
<h2 id="Region-In-Trasition_u673A_u5236"><a href="#Region-In-Trasition_u673A_u5236" class="headerlink" title="Region-In-Trasition机制"></a>Region-In-Trasition机制</h2><p>从字面意思来看，Region-In-Transition说的是Region变迁机制，实际上是指在一次特定操作行为中Region状态的变迁，那这里就涉及这么几个问题：Region存在多少种状态？HBase有哪些操作会触发Region状态变迁？一次正常操作过程中Region状态变迁的完整流程是怎么样的？如果Region状态在变迁的过程中出现异常又会怎么样？</p>
<h2 id="Region_u5B58_u5728_u591A_u5C11_u79CD_u72B6_u6001_uFF1F_u6709_u54EA_u4E9B_u64CD_u4F5C_u4F1A_u89E6_u53D1_u72B6_u6001_u53D8_u8FC1_uFF1F"><a href="#Region_u5B58_u5728_u591A_u5C11_u79CD_u72B6_u6001_uFF1F_u6709_u54EA_u4E9B_u64CD_u4F5C_u4F1A_u89E6_u53D1_u72B6_u6001_u53D8_u8FC1_uFF1F" class="headerlink" title="Region存在多少种状态？有哪些操作会触发状态变迁？"></a>Region存在多少种状态？有哪些操作会触发状态变迁？</h2><p>HBase在RegionState类中定义了Region的主要状态，主要有如下：<br><img src="/images/15243097741593.jpg" alt="rit state"><br>上图中实际上定义了四种会触发Region状态变迁的操作以及操作对应的Region状态。其中特定操作行为通常包括assign、unassign、split以及merge等，而很多其他操作都可以拆成unassign和assign，比如move操作实际上是先unassign再assign；</p>
<h2 id="Region_u72B6_u6001_u8FC1_u79FB_u662F_u5982_u4F55_u53D1_u751F_u7684_uFF1F"><a href="#Region_u72B6_u6001_u8FC1_u79FB_u662F_u5982_u4F55_u53D1_u751F_u7684_uFF1F" class="headerlink" title="Region状态迁移是如何发生的？"></a>Region状态迁移是如何发生的？</h2><p>这个过程有点类似于状态机，也是通过事件驱动的。和Region状态一样，HBase还定义了很多事件（具体见EventType类）。此处以unassign过程为例说明事件是如何驱动状态变迁的，见下图：<br><img src="/images/15243098227995.png" alt="hbase-move"></p>
<p>上图所示是Region在close时的状态变迁图，其中红字部分就是发生的各种事件。可见，如果发生M_ZK_REGION_CLOSING事件，Region就会从OPEN状态迁移到PENDING_CLOSE状态，而发生RS_ZK_REGION_CLOSING事件，Region会从PENDING_CLOSE状态迁移到CLOSING状态，以此类推，发生RS_ZK_REGION_CLOSED事件，Region就会从CLOSING状态迁移到CLOSED状态。当然，除了这些事件之外，HBase还定义了很多其他事件，在此就不一一列举。截至到此，我们知道Region是一个有限状态机，那这个状态机是如何正常工作的，HMaster、RegionServer、Zookeeper又在状态机工作过程中扮演了什么角色，那就接着往下看～</p>
<h2 id="u4E00_u6B21_u6B63_u5E38_u64CD_u4F5C_u8FC7_u7A0B_u4E2DRegion_u72B6_u6001_u53D8_u8FC1_u7684_u5B8C_u6574_u6D41_u7A0B_u662F_u600E_u4E48_u6837_u7684_uFF1F"><a href="#u4E00_u6B21_u6B63_u5E38_u64CD_u4F5C_u8FC7_u7A0B_u4E2DRegion_u72B6_u6001_u53D8_u8FC1_u7684_u5B8C_u6574_u6D41_u7A0B_u662F_u600E_u4E48_u6837_u7684_uFF1F" class="headerlink" title="一次正常操作过程中Region状态变迁的完整流程是怎么样的？"></a>一次正常操作过程中Region状态变迁的完整流程是怎么样的？</h2><p>接下来本节以unassign操作为例对这个流程进行解析：</p>
<p>整个unassign操作是一个比较复杂的过程，涉及HMaster、RegionServer和Zookeeper三个组件：</p>
<ol>
<li><p>HMaster负责维护Region在整个操作过程中的状态变化，起到一个枢纽的作用。它有两个重要的HashMap数据结构，分别为regionStates和regionsInTransition，前者用来存储整个集群中所有Region及其当时状态，而后者主要存储在变迁过程中的Region及其状态，后者是前者的一个子集，不包含OPEN状态的Regions；</p>
</li>
<li><p>RegionServer负责接收HMaster的指令执行具体unassign操作，实际上就是关闭region操作；</p>
</li>
<li><p>Zookeeper负责存储操作过程中的事件，它有一个路径为/hbase/region-in-transition的节点。一旦一个Region发生unssign操作，就会在这个节点下生成一个子节点，子节点的内容是一个“事件”经过序列化的字符串，并且Master会监听在这个子节点上，一旦发生任何事件，Master就会监听到并更新Region的状态。</p>
</li>
</ol>
<p>下图是整个流程示意图：<br><img src="/images/15243098545078.png" alt="hbase-assign"></p>
<ol>
<li><p>HMaster先执行事件M_ZK_REGION_CLOSING并更新RegionStates，将该Region的状态改为PENDING_CLOSE，并在regionsInTransition中插入一条记录；</p>
</li>
<li><p>发送一条RPC命令给拥有该Region的RegionServer，责令其关闭该Region;</p>
</li>
<li><p>RegionServer接收到HMaster发送过来的命令之后，首先生成一个RS_ZK_REGION_CLOSING事件，更新到Zookeeper，Master监听到ZK节点变动之后更新regionStates，将该Region的状态改为CLOSING;</p>
</li>
<li><p>RegionServer执行真正的Region关闭操作：如果该Region正在执行flush或者compaction，等待操作完成；否则将该Region下的所有Memstore强制flush;</p>
</li>
<li><p>完成之后生成事件RS_ZK_REGION_CLOSED，更新到Zookeeper，Master监听到ZK节点变动之后更新regionStates，将该Region的状态改为CLOSED;</p>
</li>
</ol>
<p>到这里，基本上将unssign操作过程中涉及到的Region状态变迁解释清楚了，当然，其他诸如assign操作基本类似，在此不再赘述。这里其实还有一个问题，即关于HMaster上所有Region状态是否需要持久化的问题，刚开始接触这个问题的时候想想并不需要，这些处于RIT的状态信息完全可以通过Zookeeper上/region-in-transition的子节点信息构建出来。然而，在阅读HBase Book的相关章节时，看到如下信息：</p>
<p>于是就充满了疑惑，一方面Master更新hbase:meta是一个远程操作，代价相对很大；另一方面Region状态内存更新和远程更新保证一致性比较困难；再者，Zookeeper上已经有相应RIT信息，再持久化一份并没有太大意义。为了对其进行确认，就查阅跟踪了一下源码，发现是否持久化取决于一个参数：hbase.assignment.usezk，默认情况下该参数为true，表示使用zk情况下并不会对Region状态进行持久化（详见RegionStateStore类），可见HBase Book的那段说明存在问题，在此特别说明～</p>
<p>如果Region状态在变迁的过程中出现异常会怎么样？<br>再回顾unassign的整个过程就会发现一次完整操作涉及太多流程，任何异常都可能会导致Region处于较长时间的RIT状态，好在HBase针对常见的异常做了最基本的容错处理：</p>
<ol>
<li>Master宕机重启：Master在宕机之后会丢失所有内存中的信息，也包括RIT信息以及Region状态信息，因此在重启之后会第一时间重建这些信息。重启之后会遍历Zookeeper上/hbase/regions-in-transition节点下的所有子节点，解析所有子节点对应的最后一个‘事件’，解析完成之后一方面借此重建全局的Region状态，另一方面根据状态机转移图对处于RIT状态的Region进行处理。比如如果发现当前Region的状态是PENDING_CLOSE，Master就会再次据此向RegionServer发送’关闭Region’的RPC命令。</li>
</ol>
<ol>
<li>其他异常宕机：HBase会在后台开启一个线程定期检查内存中处于RIT中的Region，一旦这些Region处于RIT状态的时长超过一定的阈值（由参数hbase.master.assignment.timeoutmonitor.timeout定义，默认600000ms）就会重新执行unassign或者assign操作。比如如果当前Region的状态是PENDING_CLOSE，而且处于该状态的时间超过了600000ms，Master就会重新执行unassign操作，向RegionServer再次发送’关闭Region’的RPC命令。</li>
</ol>
<p>可见，HBase提供了基本的重试机制，保证在一些短暂异常的情况下能够通过不断重试拉起那些处于RIT状态的Region，进而保证操作的完整性和状态的一致性。然而不幸的是，因为各种各样的原因，很多Region还是会掉入长时间的RIT状态，甚至是永久的RIT状态，必须人为干预才能解决，下面一节内容让我们看看都有哪些常见的场景会导致Region会处于永久RIT状态，以及遇到这类问题应该如何解决。</p>
<h2 id="u6C38_u4E45RIT_u72B6_u6001_u6848_u4F8B_u5206_u6790"><a href="#u6C38_u4E45RIT_u72B6_u6001_u6848_u4F8B_u5206_u6790" class="headerlink" title="永久RIT状态案例分析"></a>永久RIT状态案例分析</h2><p>通过RIT机制的了解，其实可以发现处于RIT状态Region并不是什么怪物，大部分处于RIT状态的Region都是短暂的，即使在大多数短暂异常的情况下HBase也提供了重试机制保证Region能够很快恢复正常。然而在一些特别极端的场景下还是会发生一些异常导致部分Region掉入永久的RIT状态，进而会引起表读写阻塞甚至整个集群的读写阻塞。下面我们举两个相关的案例进行说明：</p>
<h3 id="u6848_u4F8B_u4E00_uFF1ACompaction_u6C38_u4E45_u963B_u585E"><a href="#u6848_u4F8B_u4E00_uFF1ACompaction_u6C38_u4E45_u963B_u585E" class="headerlink" title="案例一：Compaction永久阻塞"></a>案例一：Compaction永久阻塞</h3><p>现象：线上一个集群因为未知原因忽然就卡住了，读写完全进不来了；另外还有很多处于PENDING_CLOSE状态的Region。</p>
<p>分析：集群卡住常见原因无非两个，一是Memstore总消耗内存大小超过了上限进而触发RegionServer级别flush，此时系统会阻塞集群执行长时间flush操作；二是storefile数量过多超过设定的上限阈值（参见：hbase.hstore.blockingStoreFiles），此时系统会阻塞所有flush请求而执行compaction。</p>
<h3 id="u8BCA_u65AD_uFF1A"><a href="#u8BCA_u65AD_uFF1A" class="headerlink" title="诊断："></a>诊断：</h3><p>（1）首先查看了各个RegionServer上的Memstore使用大小，并没有达到设定的upperLimit。</p>
<p>（2）再查看了一下所有RegionServer的storefile数量，瞬间石化了，store数为250的RegionServer上storefile数量竟然达到了1.5w+，很多单个store的storefile都超过了设定阈值100</p>
<p>（3）初步怀疑是因为storefile数量过多引起的，看到这么多storefile的第一反应是手动执行major_compaction，然而所有的compact命令好像都没有起任何作用</p>
<p>（4）无意中发现所有RegionServer的Compaction任务都是同一张表music_actions的，而且Compaction时间都基本持续了一两天。到此基本可以确认是因为表music_actions的Compaction任务长时间阻塞，占用了所有的Compaction线程资源，导致集群中所有其他表都无法执行Compaction任务，最后导致StoreFile大量堆积</p>
<p>（5）那为什么会存在PENDING_CLOSE状态的Region呢？经查看，这些处于PENDING_CLOSE状态的Region全部来自于表music_actions，进一步诊断确认是由于在执行graceful_stop过程中unassign时遇到Compaction长时间阻塞导致RegionServer无法执行Region关闭（参考上文unassign过程），因而掉入了永久RIT</p>
<h3 id="u89E3_u51B3_u65B9_u6848_uFF1A"><a href="#u89E3_u51B3_u65B9_u6848_uFF1A" class="headerlink" title="解决方案："></a>解决方案：</h3><p>（1）这个问题中RIT和集群卡住原因都在于music_actions这张表的Compaction阻塞，因此需要定位Compaction阻塞的具体原因。经过一段时间的定位初步怀疑是因为这张表的编码导致，anyway，具体原因不重要，因为一旦Compaction阻塞，好像是没办法通过正常命令解除这种阻塞的。临时有用的办法是增大集群的Compaction线程，以期望有更多空闲线程可以处理集群中其他Compaction任务，消化大量堆积的StoreFiles</p>
<p>（2）而永久性消灭这种Compaction阻塞只能先将这张表数据迁移出来，然后将这张表暴力删除。暴力删除就是先将HDFS对应文件删除，再将hbase:meta中该表对应的相关数据清除，最后重启整个集群即可。这张表删除之后使用hbck检查一致性之后，集群Compaction阻塞现象就消失了，集群就完全恢复正常。</p>
<h3 id="u6848_u4F8B_u4E8C_uFF1AHDFS_u6587_u4EF6_u5F02_u5E38"><a href="#u6848_u4F8B_u4E8C_uFF1AHDFS_u6587_u4EF6_u5F02_u5E38" class="headerlink" title="案例二：HDFS文件异常"></a>案例二：HDFS文件异常</h3><p>现象：线上集群很多RegionServer短时间内频频宕机，有几个Region处于FAILED_OPEN状态</p>
<p>分析诊断：</p>
<p>（1）查看系统监控以及RegionServer日志，确认RegionServer频繁宕机是因为大量CLOSE_WAIT状态的短连接导致。监控显示短时间内（4h）CLOSE_WAIT的数量从0增长到6w+。</p>
<p>（2）再查看RegionServer日志查看到如下日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2016-07-27 09:42:14,932 [RS_OPEN_REGION-inspur250.photo.163.org,60020,1469581282053-0] ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler - Failed open of region=news_user_actions,|u:cfcd208495d565ef66e7dff9f98764da</span><br><span class="line">|1462799167|30671473410714402,1469522128310.3b3ae24c65fc5094bc2acfebaa7a56de., starting to roll back the global memstore size.</span><br><span class="line">java.io.IOException: java.io.IOException: java.io.FileNotFoundException: File does not exist: /hbase/news_user_actions/b7b3faab86527b88a92f2a248a54d3dc/meta/0f47cda55fa44cf9aa2599079894aed6</span><br><span class="line">2016-07-27 09:42:14,934 [RS_OPEN_REGION-inspur250.photo.163.org,60020,1469581282053-0] INFO  org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler - Opening of region &#123;NAME =&gt; &apos;news_user_actions,|u:cfcd208495d565ef66e7dff9f9</span><br><span class="line">8764da|1462799167|30671473410714402,1469522128310.3b3ae24c65fc5094bc2acfebaa7a56de.&apos;, STARTKEY =&gt; &apos;|u:cfcd208495d565ef66e7dff9f98764da|1462799167|30671473410714402&apos;, ENDKEY =&gt; &apos;|u:d0&apos;, ENCODED =&gt; 3b3ae24c65fc5094bc2acfebaa7a56de,&#125; faile</span><br><span class="line">d, marking as FAILED_OPEN in ZK</span><br></pre></td></tr></table></figure>
<p>日志显示，Region ‘3b3ae24c65fc5094bc2acfebaa7a56de’打开失败，因此状态被设置为FAILED_OPEN，原因初步认为是FileNotFoundException导致，找不到的文件是Region ‘b7b3faab86527b88a92f2a248a54d3dc’ 下的一个文件，这两者之间有什么联系呢？</p>
<p>（3）使用hbck检查了一把，得到如下错误信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Found lingering reference file hdfs://mycluster/hbase/news_user_actions/3b3ae24c65fc5094bc2acfebaa7a56de/meta/0f47cda55fa44cf9aa2599079894aed6.b7b3faab86527b88a92f2a248a54d3dc</span><br></pre></td></tr></table></figure></p>
<p>看到这里就一下恍然大悟，从引用文件可以看出来，Region ‘3b3ae24c65fc5094bc2acfebaa7a56de’是‘ b7b3faab86527b88a92f2a248a54d3dc’的子Region，熟悉Split过程的童鞋就会知道，父Region分裂成两个子Region其实并没有涉及到数据文件的分裂，而是会在子Region的HDFS目录下生成一个指向父Region目录的引用文件，直到子Region执行Compaction操作才会将父Region的文件合并过来。</p>
<p>到这里，就可以理解为什么子Region会长时间处于FAILED_OPEN状态：因为子Region引用了父Region的文件，然而父Region的文件因为未知原因丢失了，所以子Region在打开的时候因为找不到引用文件因而会失败。而这种异常并不能通过简单的重试可以解决，所以会长时间掉入RIT状态。</p>
<p>（4）现在基本可以通过RegionServer日志和hbck日志确定Region处于FAILED_OPEN的原因是因为子Region所引用的父Region的文件丢失导致。那为什么会出现CLOSE_WAIT数量暴涨的问题呢？经确认是因为Region在打开的时候会读取Region对应HDFS相关文件，但因为引用文件丢失所以读取失败，读取失败之后系统会不断重试，每次重试都会同datanode建立短连接，这些短连接因为hbase的bug一直得不到合理处理就会引起CLOSEE_WAIT数量暴涨。</p>
<p>解决方案：删掉HDFS上所有检查出来的引用文件即可</p>
<h2 id="u6848_u4F8B_u5206_u6790"><a href="#u6848_u4F8B_u5206_u6790" class="headerlink" title="案例分析"></a>案例分析</h2><p>经过上面两个案例的讲解其实看出得出这么几点：</p>
<ol>
<li><p>永久性掉入RIT状态其实出现的概率并不高，都是在一些极端情况下才会出现。绝大部分RIT状态都是暂时的。</p>
</li>
<li><p>一旦掉入永久性RIT状态，说明一定有根本性的问题原因，只有定位出这些问题才能彻底解决问题</p>
</li>
<li><p>如果Region长时间处于PENDING_CLOSE或者CLOSING状态，一般是因为RegionServer在关闭Region的时候遇到了长时间Compaction任务或Flush任务，所以如果Region在做类似于Major_Compact的操作时尽量不要执行unassign操作，比如move操作、disable操作等；而如果Region长时间处于FAILED_OPEN状态，一般是因为HDFS文件出现异常所致，可以通过RegionServer日志以及hbck定位出来</p>
</li>
</ol>
<h2 id="u5199_u5728_u6587_u7AE0_u6700_u540E"><a href="#u5199_u5728_u6587_u7AE0_u6700_u540E" class="headerlink" title="写在文章最后"></a>写在文章最后</h2><p>RIT在很多运维HBase的人看来是一个很神秘的东西，这是因为RIT很少出现，而一旦出现就很致命，运维起来往往不知所措。本文就希望能够打破这种神秘感，还原它的真实本性。文章第一部分通过层层递进的方式介绍了Region-In-Transition机制，第二部分通过生产环境的真实案例分析永久性RIT出现的场景以及应对的方案。希望大家能够更多的了解RIT，通过不断的运维实践最后再也不用惧怕它～～</p>
<p>转载 <a href="http://hbasefly.com/2016/09/08/hbase-rit/" target="_blank" rel="noopener">http://hbasefly.com/2016/09/08/hbase-rit/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/07/27/hbase-minor-vs-major-compaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/07/27/hbase-minor-vs-major-compaction/" itemprop="url">hbase 压缩合并中的minor与major区别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-07-27T08:23:59+08:00">
                2016-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>HRegoin Server上的storefile文件是被后台线程监控的，以确保这些文件保持在可控状态。磁盘上的storefile的数量会随着越来越多的memstore被刷新而变等于来越多——每次刷新都会生成一个storefile文件。当storefile数量满足一定条件时（可以通过配置参数类调整），会触发文件合并操作——minor compaction，将多个比较小的storefile合并成一个大的storefile文件，直到合并的文件大到超过单个文件配置允许的最大值时会触发一次region的自动分割，即region split操作，将一个region平分成2个，具体过程以后再说，这里不再赘述。 </p>
<p>合并操作有两种类型：轻量级的的minor compaction和重量级的major compaction。<br>Minor compaction主要负责将符合条件的最早生成的几个storefile合并生成一个大的storefile文件，它不会删除被标记为”删除”的数据和以过期的数据，并且执行过一次minor合并操作后还会有多个storefile文件。<br>Minor compaction一次合并的文件数量由hbase.hstore.compaction.min(执行minor compaction的最少文件数)配置参数决定，该参数值的默认配置是3。该参数配置太大则会延迟触发minor合并操作，并且一次合并的文件数太多会占用更多的资源和执行更长的时间，这会带来不好的用户体验——毕竟hbase是要提供实时响应的。<br>在一次minor操作一次最多允许10个文件，通过hbase.hstore.compaction.max参数设置，任何一个大于hbase.hstore.compaction.min.size值的storefile文件将自动成为将要被合并的storefile，hbase.hstore.compaction.min.size属性值与被用来设置将memstore执行flush操作的配置属性hbase.hregion.memstore.flush.size的值(默认为128MB)相同。<br>Minor compaction操作有一个时间轴而的概念，那就是每次合并操作都是按storefile的生成时间有旧到新来合并文件的。如此下图所示：<br><img src="/images/15243099232075.jpg" alt="minor compaction"></p>
<p>对比Minor compaction，Major compaction操作会把所有的storefile合并成一个单一的storefile文件，在文件合并期间系统会删除标记为”删除”标记的数据和过期失效的数据，同时会block所有客户端对该操作所属的region的请求直到合并完毕，最后删除已合并的storefile文件。 </p>
<p>到底如何决定触发那种类型的major类型的compaction操作呢？这是在compaction检查执行时被自动决定的。compaction检查可以通过以下三种条件触发：<br>1、每当memstore被刷新到磁盘后触发；<br>2、通过hbase shell命令行调用或API调用触发；<br>3、通过一个叫CompacionChecker的后台线程触发。<br>每一个region都运行着一个这样的后台线程。CompacionChecker会定期的执行compation检查，时间间隔可以通过hbase.server.thread.wakefrequency来配置。<br>可以通过hbase shell命令行调用或majorCompact()API调用，从而强迫major合并操作执行，否则服务器会首先基于hbase.hregion.majorcompaction(24小时)的配置来检查是否要执行major合并操作。<br>由于Major compaction在执行期间会阻塞所有客户端的请求直到合并完毕，因此最好在服务器空闲时通过手工或脚本的方式调用执行，以提高客户体验。 </p>
<p>以下是两种compaction的区别：<br><img src="/images/15243099515674.jpg" alt="minor vs major"></p>
<p>转载 <a href="http://flyingdutchman.iteye.com/blog/1846031" target="_blank" rel="noopener">http://flyingdutchman.iteye.com/blog/1846031</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/07/27/es-flush-vs-refresh/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/07/27/es-flush-vs-refresh/" itemprop="url">elasticsearch中的refresh和flush区别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-07-27T07:18:40+08:00">
                2016-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="elasticsearch_u4E2D_u6709_u4E24_u4E2A_u6BD4_u8F83_u91CD_u8981_u7684_u64CD_u4F5C_uFF1Arefresh__u548C_flush"><a href="#elasticsearch_u4E2D_u6709_u4E24_u4E2A_u6BD4_u8F83_u91CD_u8981_u7684_u64CD_u4F5C_uFF1Arefresh__u548C_flush" class="headerlink" title="elasticsearch中有两个比较重要的操作：refresh 和 flush"></a>elasticsearch中有两个比较重要的操作：refresh 和 flush</h3><h3 id="refresh_u64CD_u4F5C"><a href="#refresh_u64CD_u4F5C" class="headerlink" title="refresh操作"></a>refresh操作</h3><p>当我们向ES发送请求的时候，我们发现es貌似可以在我们发请求的同时进行搜索。而这个实时建索引并可以被搜索的过程实际上是一次es 索引提交（commit）的过程，如果这个提交的过程直接将数据写入磁盘（fsync）必然会影响性能，所以es中设计了一种机制，即：先将index-buffer中文档（document）解析完成的segment写到filesystem cache之中，这样避免了比较损耗性能io操作，又可以使document可以被搜索。以上从index-buffer中取数据到filesystem cache中的过程叫做refresh。</p>
<p>refresh操作可以通过API设置：<br>POST /index/_settings<br>{“refresh_interval”: “10s”}<br>当我们进行大规模的创建索引操作的时候，最好将将refresh关闭。<br>POST /index/_settings<br>{“refresh_interval”: “-1″}<br>es默认的refresh间隔时间是1s，这也是为什么ES可以进行近乎实时的搜索。</p>
<h3 id="flush_u64CD_u4F5C_u4E0Etranslog"><a href="#flush_u64CD_u4F5C_u4E0Etranslog" class="headerlink" title="flush操作与translog"></a>flush操作与translog</h3><p>我们可能已经意识到如果数据在filesystem cache之中是很有可能在意外的故障中丢失。这个时候就需要一种机制，可以将对es的操作记录下来，来确保当出现故障的时候，保留在filesystem的数据不会丢失，并在重启的时候可以从这个记录中将数据恢复过来。elasticsearch提供了translog来记录这些操作。<br>当向elasticsearch发送创建document索引请求的时候，document数据会先进入到index buffer之后，与此同时会将操作记录在translog之中，当发生refresh时（数据从index buffer中进入filesystem cache的过程）translog中的操作记录并不会被清除，而是当数据从filesystem cache中被写入磁盘之后才会将translog中清空。而从filesystem cache写入磁盘的过程就是flush。可能有点晕，我画了一个图帮大家理解这个过程：<br><img src="/images/es-refresh-flush.jpg" alt="elasticsearch"></p>
<h3 id="u603B_u7ED3_u4E00_u4E0Btranslog_u7684_u529F_u80FD_uFF1A"><a href="#u603B_u7ED3_u4E00_u4E0Btranslog_u7684_u529F_u80FD_uFF1A" class="headerlink" title="总结一下translog的功能："></a>总结一下translog的功能：</h3><p>1.保证在filesystem cache中的数据不会因为elasticsearch重启或是发生意外故障的时候丢失。<br>2.当系统重启时会从translog中恢复之前记录的操作。<br>3.当对elasticsearch进行CRUD操作的时候，会先到translog之中进行查找，因为tranlog之中保存的是最新的数据。<br>4.translog的清除时间时进行flush操作之后（将数据从filesystem cache刷入disk之中）。<br>再总结一下flush操作的时间点：</p>
<p>1.es的各个shard会每个30分钟进行一次flush操作。<br>2.当translog的数据达到某个上限的时候会进行一次flush操作。<br>有关于translog和flush的一些配置项：</p>
<p>index.translog.flush_threshold_ops:当发生多少次操作时进行一次flush。默认是 unlimited。<br>index.translog.flush_threshold_size:当translog的大小达到此值时会进行一次flush操作。默认是512mb。<br>index.translog.flush_threshold_period:在指定的时间间隔内如果没有进行flush操作，会进行一次强制flush操作。默认是30m。<br>index.translog.interval:多少时间间隔内会检查一次translog，来进行一次flush操作。es会随机的在这个值到这个值的2倍大小之间进行一次操作，默认是5s。<br>参考：<a href="http://www.elastic.co/guide/en/elasticsearch/guide/current/near-real-time.html" target="_blank" rel="noopener">http://www.elastic.co/guide/en/elasticsearch/guide/current/near-real-time.html</a><br>           <a href="http://www.elastic.co/guide/en/elasticsearch/guide/current/translog.html" target="_blank" rel="noopener">http://www.elastic.co/guide/en/elasticsearch/guide/current/translog.html</a></p>
<p>转载 <a href="http://www.yubingzhe.com/143.html" target="_blank" rel="noopener">http://www.yubingzhe.com/143.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/07/10/scala-note-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/07/10/scala-note-3/" itemprop="url">scala学习笔记(三)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-07-10T21:08:00+08:00">
                2016-07-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scala/" itemprop="url" rel="index">
                    <span itemprop="name">scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u5982_u4F55_u4F7F_u7528_scala__u7684range__u51FD_u6570"><a href="#u5982_u4F55_u4F7F_u7528_scala__u7684range__u51FD_u6570" class="headerlink" title="如何使用 scala 的range 函数"></a>如何使用 scala 的range 函数</h2><p>在 scala 应用中可以看到有不同的方法使用 range<br> Range 在常用的数据结构中经常用到，用于循环中的迭代元素，并且提供了几个强大的方法<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="number">1</span> to <span class="number">10</span></span><br><span class="line">res0: scala.collection.immutable.<span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="number">1</span> until <span class="number">10</span></span><br><span class="line">res1: scala.collection.immutable.<span class="type">Range</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="number">1</span> to <span class="number">10</span> by <span class="number">2</span></span><br><span class="line">res2: scala.collection.immutable.<span class="type">Range</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; 'a' to 'c'</span><br><span class="line">res3: collection.immutable.<span class="type">NumericRange</span>.<span class="type">Inclusive</span>[<span class="type">Char</span>] = <span class="type">NumericRange</span>(a, b, c)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = (<span class="number">1</span> to <span class="number">10</span>).toList</span><br><span class="line">x: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = (<span class="number">1</span> to <span class="number">10</span>).toArray</span><br><span class="line">x: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = (<span class="number">1</span> to <span class="number">10</span>).toSet</span><br><span class="line">x: scala.collection.immutable.<span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>(<span class="number">5</span>, <span class="number">10</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">Array</span>.range(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">x: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">Vector</span>.range(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">x: collection.immutable.<span class="type">Vector</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">List</span>.range(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">x: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">List</span>.range(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">x: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = collection.mutable.<span class="type">ArrayBuffer</span>.range('a', 'd')</span><br><span class="line">x: scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Char</span>] = <span class="type">ArrayBuffer</span>(a, b, c)</span><br></pre></td></tr></table></figure></p>
<p>也可以用tabulate方法实现填充集合<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">List</span>.tabulate(<span class="number">5</span>)(_ + <span class="number">1</span>)</span><br><span class="line">x: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">List</span>.tabulate(<span class="number">5</span>)(_ + <span class="number">2</span>)</span><br><span class="line">x: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">Vector</span>.tabulate(<span class="number">5</span>)(_ * <span class="number">2</span>)</span><br><span class="line">x: scala.collection.immutable.<span class="type">Vector</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/03/19/scala-note-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/19/scala-note-2/" itemprop="url">scala学习笔记(二)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-19T10:23:48+08:00">
                2016-03-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scala/" itemprop="url" rel="index">
                    <span itemprop="name">scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="scala_u8BBF_u95EE_u4FEE_u9970_u7B26"><a href="#scala_u8BBF_u95EE_u4FEE_u9970_u7B26" class="headerlink" title="scala访问修饰符"></a>scala访问修饰符</h2><p>包，类或对象的成员可以标记访问修饰符private和protected，如果我们不使用这两种关键字，那么访问将被默认设置为public。这些修饰 限制为成员的代码的某些区域访问。</p>
<h3 id="u79C1_u6709_u6210_u5458"><a href="#u79C1_u6709_u6210_u5458" class="headerlink" title="私有成员"></a>私有成员</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">   <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;</span><br><span class="line">      <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>() &#123; println(<span class="string">"f"</span>) &#125;</span><br><span class="line">      <span class="class"><span class="keyword">class</span> <span class="title">InnerMost</span> </span>&#123;</span><br><span class="line">         f() <span class="comment">// OK</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   (<span class="keyword">new</span> <span class="type">Inner</span>).f() <span class="comment">// Error: f is not accessible</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在Scala中，访问 (new Inner).f() 是非法的，因为f被声明为private内部类并且访问不是在内部类内。与此相反，到f第一接入类最内层是确定的，因为该访问包含在类内的主体。 Java将允许这两种访问，因为它可以让其内部类的外部类访问私有成员。</p>
</blockquote>
<h3 id="u4FDD_u62A4_u6210_u5458"><a href="#u4FDD_u62A4_u6210_u5458" class="headerlink" title="保护成员"></a>保护成员</h3><p>在 scala 中，对保护（Protected）成员的访问比 java 更严格一些。因为它只允许保护成员在定义了该成员的的类的子类中被访问。而在java中，用protected关键字修饰的成员，除了定义了该成员的类的子类可以访问，同一个包里的其他类也可以进行访问。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> p &#123;</span><br><span class="line">   <span class="class"><span class="keyword">class</span> <span class="title">Super</span> </span>&#123;</span><br><span class="line">      <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>() &#123; println(<span class="string">"f"</span>) &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="class"><span class="keyword">class</span> <span class="title">Sub</span> <span class="keyword">extends</span> <span class="title">Super</span> </span>&#123;</span><br><span class="line">      f()</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="class"><span class="keyword">class</span> <span class="title">Other</span> </span>&#123;</span><br><span class="line">     (<span class="keyword">new</span> <span class="type">Super</span>).f() <span class="comment">// Error: f is not accessible</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>上例中，Sub 类对 f 的访问没有问题，因为 f 在 Super 中被声明为 protected，而 Sub 是 Super 的子类。相反，Other 对 f 的访问不被允许，因为 other 没有继承自 Super。而后者在 java 里同样被认可，因为 Other 与 Sub 在同一包里。</p>
<h3 id="u516C_u5171_28Public_29_u6210_u5458"><a href="#u516C_u5171_28Public_29_u6210_u5458" class="headerlink" title="公共(Public)成员"></a>公共(Public)成员</h3><p>Scala中，如果没有指定任何的修饰符，则默认为 public。这样的成员在任何地方都可以被访问。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">   <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>() &#123; println(<span class="string">"f"</span>) &#125;</span><br><span class="line">      <span class="class"><span class="keyword">class</span> <span class="title">InnerMost</span> </span>&#123;</span><br><span class="line">         f() <span class="comment">// 正确</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   (<span class="keyword">new</span> <span class="type">Inner</span>).f() <span class="comment">// 正确因为 f() 是 public</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="u4F5C_u7528_u57DF_u4FDD_u62A4"><a href="#u4F5C_u7528_u57DF_u4FDD_u62A4" class="headerlink" title="作用域保护"></a>作用域保护</h3><p>Scala中，访问修饰符可以通过使用限定词强调。格式为:<br>private[x] </p>
<p>或 </p>
<p>protected[x]<br>这里的x指代某个所属的包、类或单例对象。如果写成private[x],读作”这个成员除了对[…]中的类或[…]中的包中的类及它们的伴生对像可见外，对其它所有类都是private。<br>这种技巧在横跨了若干包的大型项目中非常有用，它允许你定义一些在你项目的若干子包中可见但对于项目外部的客户却始终不可见的东西。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> bobsrocckets&#123;</span><br><span class="line">    <span class="keyword">package</span> navigation&#123;</span><br><span class="line">        <span class="keyword">private</span>[bobsrockets] <span class="class"><span class="keyword">class</span> <span class="title">Navigator</span></span>&#123;</span><br><span class="line">         <span class="keyword">protected</span>[navigation] <span class="function"><span class="keyword">def</span> <span class="title">useStarChart</span></span>()&#123;&#125;</span><br><span class="line">         <span class="class"><span class="keyword">class</span> <span class="title">LegOfJourney</span></span>&#123;</span><br><span class="line">             <span class="keyword">private</span>[<span class="type">Navigator</span>] <span class="keyword">val</span> distance = <span class="number">100</span></span><br><span class="line">             &#125;</span><br><span class="line">            <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> speed = <span class="number">200</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">package</span> launch&#123;</span><br><span class="line">        <span class="keyword">import</span> navigation._</span><br><span class="line">        <span class="class"><span class="keyword">object</span> <span class="title">Vehicle</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span>[launch] <span class="keyword">val</span> guide = <span class="keyword">new</span> <span class="type">Navigator</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>上述例子中，类Navigator被标记为private[bobsrockets]就是说这个类对包含在bobsrockets包里的所有的类和对象可见。<br>比如说，从Vehicle对象里对Navigator的访问是被允许的，因为对象Vehicle包含在包launch中，而launch包在bobsrockets中，相反，所有在包bobsrockets之外的代码都不能访问类Navigator。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/03/16/scala-note-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/16/scala-note-1/" itemprop="url">scala学习笔记(一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-16T16:05:41+08:00">
                2016-03-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scala/" itemprop="url" rel="index">
                    <span itemprop="name">scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u57FA_u7840_u8BED_u6CD5"><a href="#u57FA_u7840_u8BED_u6CD5" class="headerlink" title="基础语法"></a>基础语法</h2><p>区分大小写 -  Scala是大小写敏感的，这意味着标识Hello 和 hello在Scala中会有不同的含义<br>类名 - 对于所有的类名的第一个字母要大写。<br>如果需要使用几个单词来构成一个类的名称，每个单词的第一个字母要大写。<br>示例：class MyFirstScalaClass<br>方法名称 - 所有的方法名称的第一个字母用小写。<br>如果若干单词被用于构成方法的名称，则每个单词的第一个字母应大写。<br>示例：def myMethodName()<br>程序文件名 - 程序文件的名称应该与对象名称完全匹配。<br>保存文件时，应该保存它使用的对象名称（记住Scala是区分大小写），并追加“.scala”为文件扩展名。 （如果文件名和对象名称不匹配，程序将无法编译）。</p>
<p>示例: 假设“HelloWorld”是对象的名称。那么该文件应保存为’HelloWorld.scala“<br>def main(args: Array[String]) - Scala程序从main()方法开始处理，这是每一个Scala程序的强制程序入口部分。</p>
<h2 id="u5B57_u7B26_u4E32"><a href="#u5B57_u7B26_u4E32" class="headerlink" title="字符串"></a>字符串</h2><p>Scala中单引号和双引号包裹是有区别的，单引号用于字符，双引号用于字符串。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> c1 = 'c'</span><br><span class="line">c1: <span class="type">Char</span> = c</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> 字符<span class="number">2</span> = '杨'</span><br><span class="line">字符<span class="number">2</span>: <span class="type">Char</span> = 杨</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> s1 = <span class="string">"scala基础语法"</span></span><br><span class="line">s1: <span class="type">String</span> = scala基础语法</span><br></pre></td></tr></table></figure></p>
<h2 id="Scala_u4FEE_u9970_u7B26_3A"><a href="#Scala_u4FEE_u9970_u7B26_3A" class="headerlink" title="Scala修饰符:"></a>Scala修饰符:</h2><p>所有的Scala的组件需要名称。使用对象，类，变量和方法名被称为标识符。关键字不能用作标识符和标识是区分大小写的。Scala支持以下四种类型标识符：</p>
<h3 id="u6587_u5B57_u6807_u8BC6_u7B26"><a href="#u6587_u5B57_u6807_u8BC6_u7B26" class="headerlink" title="文字标识符"></a>文字标识符</h3><p>字母数字标识符开始以字母或下划线，可以使用字母，数字或下划线。“$”字符在Scala中是保留关键字，标识符不能使用。以下是合法的字母标识符：</p>
<p>age, salary, _value,  __1_value<br>以下是非法标识符：</p>
<p>$salary, 123abc, -salary</p>
<h3 id="u8FD0_u7B97_u7B26_u6807_u8BC6"><a href="#u8FD0_u7B97_u7B26_u6807_u8BC6" class="headerlink" title="运算符标识"></a>运算符标识</h3><p>运算符识别符由一个或多个运算符字符。操作字符是可打印的ASCII字符，如+, :, ?, ~ 或#。以下是合法的运算符标识：</p>
<ul>
<li>++ ::: &lt;?&gt; :&gt;<br>Scala编译器将在内部“轧”操作符标识符使它们成为合法的Java标识符，并嵌入$字符。例如，所述标识符:-&gt;将内部表示为$colon$minus$greater。</li>
</ul>
<h3 id="u6DF7_u5408_u6807_u8BC6_u7B26"><a href="#u6DF7_u5408_u6807_u8BC6_u7B26" class="headerlink" title="混合标识符"></a>混合标识符</h3><p>混合标识符由一个字母数字识别符，随后是一个下划线和运算符标识。以下是合法的混合标识符：</p>
<p>unary<em>+,  myvar</em>=<br>在这里，作为一个方法名unary<em>+定义了一个一元+运算符和myvar</em>=用来作为方法名称定义了一个赋值运算符。</p>
<h3 id="u7ACB_u5373_u6570_u6807_u8BC6_u7B26"><a href="#u7ACB_u5373_u6570_u6807_u8BC6_u7B26" class="headerlink" title="立即数标识符"></a>立即数标识符</h3><p>一个文字标识是包含在反引号(<code>. . .</code>)的任意字符串。以下是合法的文字标识：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">g</span></span>(x : <span class="type">Int</span>) = <span class="number">5</span> <span class="keyword">match</span> &#123; <span class="keyword">case</span> `x` =&gt; <span class="string">"yup"</span>; <span class="keyword">case</span> _ =&gt; <span class="string">"nope"</span>&#125;</span><br><span class="line">g: (x: <span class="type">Int</span>)java.lang.<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; g(<span class="number">5</span>)</span><br><span class="line">res3: java.lang.<span class="type">String</span> = yup</span><br></pre></td></tr></table></figure></p>
<h2 id="Scala__u5305"><a href="#Scala__u5305" class="headerlink" title="Scala 包"></a>Scala 包</h2><h3 id="u5B9A_u4E49_u5305"><a href="#u5B9A_u4E49_u5305" class="headerlink" title="定义包"></a>定义包</h3><p>Scala 使用 package 关键字定义包，在Scala将代码定义到某个包中有两种方式：<br>第一种方法和 Java 一样，在文件的头定义包名，这种方法就后续所有代码都放在该报中。 比如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.runoob</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloWorld</span></span></span><br></pre></td></tr></table></figure></p>
<p>第二种方法有些类似 C#，如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.runoob &#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">HelloWorld</span> </span></span><br><span class="line"><span class="class">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>第二种方法，可以在一个文件中定义多个包。</p>
<h3 id="u5F15_u7528"><a href="#u5F15_u7528" class="headerlink" title="引用"></a>引用</h3><p>Scala 使用 import 关键字引用包。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.awt.<span class="type">Color</span>  <span class="comment">// 引入Color</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.awt._  <span class="comment">// 引入包内所有成员</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span></span>(evt: event.<span class="type">ActionEvent</span>) &#123; <span class="comment">// java.awt.event.ActionEvent</span></span><br><span class="line">  ...  <span class="comment">// 因为引入了java.awt，所以可以省去前面的部分</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>import语句可以出现在任何地方，而不是只能在文件顶部。import的效果从开始延伸到语句块的结束。这可以大幅减少名称冲突的可能性。<br>如果想要引入包中的几个成员，可以使用selector（选取器）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.awt.&#123;<span class="type">Color</span>, <span class="type">Font</span>&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 重命名成员</span></span><br><span class="line"><span class="keyword">import</span> java.util.&#123;<span class="type">HashMap</span> =&gt; <span class="type">JavaHashMap</span>&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 隐藏成员</span></span><br><span class="line"><span class="keyword">import</span> java.util.&#123;<span class="type">HashMap</span> =&gt; _, _&#125; <span class="comment">// 引入了util包的所有成员，但是HashMap被隐藏了</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：默认情况下，Scala 总会引入 java.lang.<em> 、 scala.</em> 和 Predef._，这里也能解释，为什么以scala开头的包，在使用时都是省去scala.的。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/02/27/how-many-shards-index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/02/27/how-many-shards-index/" itemprop="url">Optimizing Elasticsearch-How Many Shards per Index</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-02-27T10:58:40+08:00">
                2016-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>A key question in the minds of most Elasticsearch users when they create an index is “How many shards should I use?” In this article, we explain the design tradeoffs and performance consequences of choosing different values for the number of shards. Continue reading if you want to learn how to demystify and optimize your sharding strategy.</p>
<h3 id="Why_Bother_3F"><a href="#Why_Bother_3F" class="headerlink" title="Why Bother?"></a>Why Bother?</h3><p>This is an important topic, and many users are apprehensive as they approach it – and for good reason. A major mistake in shard allocation could cause scaling problems in a production environment that maintains an ever-growing dataset.</p>
<p>On the other hand, we know that there is little Elasticsearch documentation on this topic. Most users just want answers – and they want specific answers, not vague number ranges and warnings for arbitrarily large numbers.</p>
<p>Well, we have some answers. After covering a few definitions and some clarifications, we present several common use cases and provide our recommendations for each.</p>
<h3 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h3><p>If you’re fairly new to Elasticsearch, it’s important that you understand the basic jargon and grasp the elemental concepts. </p>
<p>(If you have some expertise with ES, you might want to skip to the next section.)</p>
<p>Consider this simple diagram of an Elasticsearch cluster:”&gt;”&gt;<br><img src="https://qbox.io/img/blog/elasticsearch_cluster.png?t=1439423553643&amp;width=700" alt="es element"><br>Remember these definitions while refering to this diagram:</p>
<p>“&gt;</p>
<p>cluster – An Elasticsearch cluster consists of one or more nodes and is identifiable by its cluster name.</p>
<p>node – A single Elasticsearch instance. In most environments, each node runs on a separate box or virtual machine.</p>
<p>index – In Elasticsearch, an index is a collection of documents.</p>
<p>shard – Because Elasticsearch is a distributed search engine, an index is usually split into elements known as shards that are distributed across multiple nodes. Elasticsearch automatically manages the arrangement of these shards. It also rebalances the shards as necessary, so users need not worry about the details.</p>
<p>replica – By default, Elasticsearch creates five primary shards and one replica for each index. This means that each index will consist of five primary shards, and each shard will have one copy.</p>
<p>Allocating multiple shards and replicas is the essence of the design for distributed search capability, providing for high availability and quick access in searches against the documents within an index. The main difference between a primary and a replica shard is that only the primary shard can accept indexing requests. Both replica and primary shards can serve querying requests.</p>
<p>In the diagram above, we have an Elasticsearch cluster consisting of two nodes in a default shard configuration. Elasticsearch automatically arranges the five primary shards split across the two nodes. There is one replica shard that corresponds to each primary shard, but the arrangement of these replica shards is altogether different from that of the primary shards. Again, think distribution.</p>
<p>Allow us to clarify: Remember, the number_of_shards value pertains to indexes—not to the cluster as whole. This value specifies the number of shards for <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html" target="_blank" rel="noopener">each index</a>(not the total primary shards in the cluster).</p>
<h3 id="A_Word_about_Replicas"><a href="#A_Word_about_Replicas" class="headerlink" title="A Word about Replicas"></a>A Word about Replicas</h3><p>We don’t elaborate in this article on Elasticsearch replicas. That is an entirely separate topic that <a href="http://blog.qbox.io/announcing-replicated-elasticsearch-clusters" target="_blank" rel="noopener">we cover elsewhere</a>. Replicas are primarily for search performance, and a user can add or remove them at any time. As we explain in <a href="http://blog.qbox.io/announcing-replicated-elasticsearch-clusters" target="_blank" rel="noopener">that article</a>, additional replicas give you additional capacity, higher throughput, and stronger failover.</p>
<h3 id="Allocate_Shards_Carefully"><a href="#Allocate_Shards_Carefully" class="headerlink" title="Allocate Shards Carefully"></a>Allocate Shards Carefully</h3><p>After you configure an Elasticsearch cluster, it’s critically important to realize that you cannot modify the shard allocation later. If you later find it necessary to change the number of shards, then you would need to reindex all the source documents. (Although reindexing is a long process, it can be done without downtime).</p>
<p>The primary shard configuration is quite analogous to a hard disk partition, in which a repartition of raw disk space requires a user to back up, configure a new partition, and rewrite data onto the new partition.</p>
<h3 id="Small_Static_Dataset_2C_2-3_GB"><a href="#Small_Static_Dataset_2C_2-3_GB" class="headerlink" title="Small Static Dataset, 2-3 GB"></a>Small Static Dataset, 2-3 GB</h3><p>The key consideration as you allocate shards is your expectation for the growth of your dataset. </p>
<p>We quite often see the tendency to unnecessarily overallocate on shard count. Since share count such a hot topic within the ES community, users may assume that overallocation is a safe bet. (By overallocation, we simply mean specifying more shards per index than is necessary for the current size (document count) for a particular dataset.)</p>
<p>Elastic was promoting this idea in the early days, but then many users began taking it too far—such as allocating 1,000 shards. Elastic now provides a bit more cautious rationale:</p>
<p>“A little overallocation is good. A kagillion shards is bad. It is difficult to define what constitutes too many shards, as it depends on their size and how they are being used. A hundred shards that are seldom used may be fine, while two shards experiencing very heavy usage could be too many.”<br>Remember that there is an additional cost for each shard that you allocate:</p>
<p>“&gt;</p>
<p>“&gt;</p>
<p>Since a shard is essentially a Lucene index, it consumes file handles, memory, and CPU resources.<br>Each search request will touch a copy of every shard in the index, which isn’t a problem when the shards are spread across several nodes. Contention arises and performance decreases when the shards are competing for the same hardware resources.<br>Elasticsearch uses <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-intro.html" target="_blank" rel="noopener">term frequency statistics to calculate relevance</a>, but these statistics correspond to individual shards. Maintaining only a small amount of data across a many shards will tend to result in poor document relevance.<br>Our customers expect their businesses to grow and their datasets to expand accordingly. There is therefore always a need for contingency planning. Many users convince themselves that they’ll encounter explosive growth (although most never actually see an unmanageable spike). In addition, we all want to minimize downtime and avoid resharding.</p>
<p>If you worry about rapid data growth, then we suggest a focus on a simple constraint: the <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/_limiting_memory_usage.html" target="_blank" rel="noopener">maximum JVM heap size recommendation for Elasticsearch</a> is approximately 30-32GB. This is a solid estimate on the limit of your absolute maximum shard size. For example, if you really think it possible that you could reach 200GB (but not much further without other infrastructure changes), then we recommend an allocation of 7 shards, or 8 shards at most.</p>
<p>By all means, don’t allocate for an inappropriately high goal of 10 terabytes that you might attain three years from now. It’s likely that you’ll see some performance strain—sooner than you like.</p>
<p>Although we aren’t explaining replicas in detail here, we do recommend that you plan for a modest number of shards and consider increasing the number of replicas. If you’re configuring a new environment, then perhaps you want to have a look at our <a href="http://blog.qbox.io/announcing-replicated-elasticsearch-clusters" target="_blank" rel="noopener">replicated clusters</a>. With a replicated cluster, you get a three-node cluster that includes one replica with an option to easily increase the number of replicas as your requirements change.</p>
<h3 id="Large_and_Growing_Dataset"><a href="#Large_and_Growing_Dataset" class="headerlink" title="Large and Growing Dataset"></a>Large and Growing Dataset</h3><p>We strongly encourage you to rely on over-allocation for large datasets—but only modestly. You can still use the 30GB maximum shard size guideline that we give above.</p>
<p>We do, however, suggest that you continue to picture the ideal scenario as being one shard per index, per node. A good launch point for capacity planning is to allocate shards with a factor of 1.5 to 3 times the number of nodes in your initial configuration. If you’re starting with 3 nodes, then we recommend that you specify at most 3 x 3 = 9 shards.</p>
<p>Your shard size may be getting too high if you’re discovering issues through the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-stats.html?q=cluster%20stat" target="_blank" rel="noopener">cluster stats APIs</a> or encountering minor performance degradations. If this is the case, simply add a node and ES will will rebalance the shards acccordingly.</p>
<p>Once again, please note that we’re omitting the specification of replicas from our discussion here. The same ideal shard guideline of one shard per index per node also holds true for replica shards. So if you need only one replica, then you’ll need twice as many nodes. Two replicas would require three times the number of nodes. For more details, see our article on <a href="http://blog.qbox.io/announcing-replicated-elasticsearch-clusters" target="_blank" rel="noopener">Replicated Clusters</a>.</p>
<p>“&gt;</p>
<h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><p>Do you accummulate daily indices and yet incur only small search loads? Perhaps these indices number in the hundreds, but each index is 1GB or smaller. For these and similar problem spaces, our simple recommendation is that you choose one shard.</p>
<p>If you roll with the defaults for Logstash (daily indices) and ES (5 shards), you could generate up to 890 shards in 6 months. Further, your cluster will be hurting—unless you have 15 nodes or more.</p>
<p>Think about it: most Logstash users are infrequent searchers, performing fewer than one query per minute. Accordingly, we recommend a simple economical setup. Since search performance isn’t a primary requirement for such cases, we don’t need multiple replicas. A single replica is enough for basic redundancy. The data-to-memory ratio can also be quite high.</p>
<p>If you go with a single shard per index, then you could probably run a Logstash configuration for 6 months on a three-node cluster. Ideally, you’d use at least 4GB, but we’d recommend 8GB because 8GB is where network speed starts to get significantly better on most cloud platforms and much less resource-sharing.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>We reiterate that shards consume resources and require processing overhead.</p>
<p>To compile results from an index consisting of more than one shard, Elasticsearch must query each shard individually (although in parallel), and then it must perform operations on the aggregated results. Because of this, a machine with more IO headroom (SSDs) and a multi-core processor can definitely benefit from sharding, but you must consider the size, volatility, and future states of your dataset. While there is no one-size-for-all with respect to shard allocation, we hope that you can benefit from this discussion.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  
    
  

  <article class="post post-type-normal post-sticky" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/01/27/spark-sort-shuffle-analyse/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                  <span class="post-sticky-flag" title="置顶">
                    <i class="fa fa-thumb-tack"></i>
                  </span>
                
                <a class="post-title-link" href="/2016/01/27/spark-sort-shuffle-analyse/" itemprop="url">Spark Sort Based Shuffle内存分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-27T17:51:18+08:00">
                2016-01-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u524D_u8A00"><a href="#u524D_u8A00" class="headerlink" title="前言"></a>前言</h2><p>借用和董神的一段对话说下背景：</p>
<p>shuffle共有三种，别人讨论的是hash shuffle，这是最原始的实现，曾经有两个版本，第一版是每个map产生r个文件，一共产生mr个文件，由于产生的中间文件太大影响扩展性，社区提出了第二个优化版本，让一个core上map共用文件，减少文件数目，这样共产生corer个文件，好多了，但中间文件数目仍随任务数线性增加，仍难以应对大作业，但hash shuffle已经优化到头了。为了解决hash shuffle性能差的问题，又引入sort shuffle，完全借鉴mapreduce实现，每个map产生一个文件，彻底解决了扩展性问题<br>目前Sort Based Shuffle 是作为默认Shuffle类型的。Shuffle 是一个很复杂的过程，任何一个环节都足够写一篇文章。所以这里，我尝试换个方式，从实用的角度出发，让读者有两方面的收获：</p>
<p>剖析哪些环节，哪些代码可能会让内存产生问题<br>控制相关内存的参数<br>有时候，我们宁可程序慢点，也不要OOM，至少要先跑步起来，希望这篇文章能够让你达成这个目标。</p>
<p>同时我们会提及一些类名，这些类方便你自己想更深入了解时，可以方便的找到他们，自己去探个究竟。</p>
<h2 id="Shuffle__u6982_u89C8"><a href="#Shuffle__u6982_u89C8" class="headerlink" title="Shuffle 概览"></a>Shuffle 概览</h2><p>Spark 的Shuffle 分为 Write,Read 两阶段。我们预先建立三个概念：</p>
<p>Write 对应的是ShuffleMapTask,具体的写操作ExternalSorter来负责</p>
<p>Read 阶段由ShuffleRDD里的HashShuffleReader来完成。如果拉来的数据如果过大，需要落地，则也由ExternalSorter来完成的</p>
<p>所有Write 写完后，才会执行Read。 他们被分成了两个不同的Stage阶段。</p>
<p>也就是说，Shuffle Write ,Shuffle Read 两阶段都可能需要落磁盘，并且通过Disk Merge 来完成最后的Sort归并排序。</p>
<h2 id="Shuffle_Write__u5185_u5B58_u6D88_u8017_u5206_u6790"><a href="#Shuffle_Write__u5185_u5B58_u6D88_u8017_u5206_u6790" class="headerlink" title="Shuffle Write 内存消耗分析"></a>Shuffle Write 内存消耗分析</h2><p>Shuffle Write 的入口链路为：</p>
<blockquote>
<p>org.apache.spark.scheduler.ShuffleMapTask<br> —&gt; org.apache.spark.shuffle.sort.SortShuffleWriter<br>  —&gt; org.apache.spark.util.collection.ExternalSorter</p>
</blockquote>
<p>会产生内存瓶颈的其实就是 org.apache.spark.util.collection.ExternalSorter。我们看看这个复杂的ExternalSorter都有哪些地方在占用内存：</p>
<p>第一个地：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> map = <span class="keyword">new</span> <span class="type">PartitionedAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br></pre></td></tr></table></figure>
<p>我们知道，数据都是先写内存，内存不够了，才写磁盘。这里的map就是那个放数据的内存了。</p>
<p>这个PartitionedAppendOnlyMap内部维持了一个数组，是这样的：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> data = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">AnyRef</span>](<span class="number">2</span> * capacity)</span><br></pre></td></tr></table></figure></p>
<p>也就是他消耗的并不是Storage的内存，所谓Storage内存，指的是由blockManager管理起来的内存。</p>
<p>PartitionedAppendOnlyMap 放不下，要落地，那么不能硬生生的写磁盘，所以需要个buffer,然后把buffer再一次性写入磁盘文件。这个buffer是由参数</p>
<p>spark.shuffle.file.buffer=32k<br>控制的。数据获取的过程中，序列化反序列化，也是需要空间的，所以Spark 对数量做了限制，通过如下参数控制：</p>
<p> spark.shuffle.spill.batchSize=10000<br>假设一个Executor的可使用的Core为 C个，那么对应需要的内存消耗为：</p>
<p> C <em> 32k + C </em> 10000个Record + C <em> PartitionedAppendOnlyMap<br>这么看来，写文件的buffer不是问题，而序列化的batchSize也不是问题，几万或者十几万个Record 而已。那C </em> PartitionedAppendOnlyMap 到底会有多大呢？我先给个结论:</p>
<p>   C <em> PartitionedAppendOnlyMap &lt; ExecutorHeapMemeory </em> 0.2 * 0.8<br>怎么得到上面的结论呢？核心店就是要判定PartitionedAppendOnlyMap 需要占用多少内存，而它到底能占用内存，则由触发写磁盘动作决定，因为一旦写磁盘，PartitionedAppendOnlyMap所占有的内存就会被释放。下面是判断是否写磁盘的逻辑代码：</p>
<blockquote>
<p>estimatedSize = map.estimateSize()<br>if (maybeSpill(map, estimatedSize)) {<br>        map = new PartitionedAppendOnlyMap[K, C]<br>}</p>
</blockquote>
<p>每放一条记录，就会做一次内存的检查，看PartitionedAppendOnlyMap 到底占用了多少内存。如果真是这样，假设检查一次内存1ms, 1kw 就不得了的时间了。所以肯定是不行的，所以 estimateSize其实是使用采样算法来做的。</p>
<p>第二个，我们也不希望mayBeSpill太耗时,所以 maybeSpill 方法里就搞了很多东西，减少耗时。我们看看都设置了哪些防线</p>
<p>首先会判定要不要执行内部逻辑：</p>
<p>   elementsRead % 32 == 0 &amp;&amp; currentMemory &gt;= myMemoryThreshold<br>每隔32次会进行一次检查，并且要当前PartitionedAppendOnlyMap currentMemory &gt; myMemoryThreshold 才会进一步判定是不是要spill.</p>
<p>其中 myMemoryThreshold可通过如下配置获得初始值</p>
<p>spark.shuffle.spill.initialMemoryThreshold =  5 <em> 1024 </em> 1024<br>接着会向 shuffleMemoryManager 要 2 * currentMemory - myMemoryThreshold 的内存，shuffleMemoryManager 是被Executor 所有正在运行的Task(Core) 共享的，能够分配出去的内存是：</p>
<p>ExecutorHeapMemeory <em> 0.2 </em> 0.8<br>上面的数字可通过下面两个配置来更改：</p>
<p>spark.shuffle.memoryFraction=0.2<br>spark.shuffle.safetyFraction=0.8<br>如果无法获取到足够的内存，就会触发真的spill操作了。</p>
<p>看到这里，上面的结论就显而易见了。</p>
<p>然而，这里我们忽略了一个很大的问题，就是</p>
<p> estimatedSize = map.estimateSize()<br>为什么说它是大问题，前面我们说了，estimateSize 是近似估计，所以有可能估的不准，也就是实际内存会远远超过预期。</p>
<p>具体的大家可以看看 org.apache.spark.util.collection.SizeTracker</p>
<p>我这里给出一个结论：</p>
<p>如果你内存开的比较大，其实反倒风险更高，因为estimateSize 并不是每次都去真实的算缓存。它是通过采样来完成的，而采样的周期不是固定的，而是指数增长的，比如第一次采样完后，PartitionedAppendOnlyMap 要经过1.1次的update/insert操作之后才进行第二次采样，然后经过1.1*.1.1次之后进行第三次采样，以此递推，假设你内存开的大，那PartitionedAppendOnlyMap可能要经过几十万次更新之后之后才会进行一次采样，然后才能计算出新的大小，这个时候几十万次更新带来的新的内存压力，可能已经让你的GC不堪重负了。</p>
<p>当然，这是一种折中，因为确实不能频繁采样。</p>
<p>如果你不想出现这种问题，要么自己替换实现这个类，要么将</p>
<p>spark.shuffle.safetyFraction=0.8<br>设置的更小一些。</p>
<p>Shuffle Read 内存消耗分析<br>Shuffle Read 的入口链路为：</p>
<p>org.apache.spark.rdd.ShuffledRDD<br>—&gt; org.apache.spark.shuffle.sort.HashShuffleReader<br>   —&gt;  org.apache.spark.util.collection.ExternalAppendOnlyMap<br>   —&gt;  org.apache.spark.util.collection.ExternalSorter<br>Shuffle Read 会更复杂些，尤其是从各个节点拉取数据。但这块不是不是我们的重点。按流程，主要有：</p>
<p>获取待拉取数据的迭代器<br>使用AppendOnlyMap/ExternalAppendOnlyMap 做combine<br>如果需要对key排序，则使用ExternalSorter<br>其中1后续会单独列出文章。3我们在write阶段已经讨论过。所以这里重点是第二个步骤，combine阶段。</p>
<p>如果你开启了</p>
<p>spark.shuffle.spill=true<br>则使用ExternalAppendOnlyMap，否则使用AppendOnlyMap。两者的区别是，前者如果内存不够，则落磁盘，会发生spill操作，后者如果内存不够，直接OOM了。</p>
<p>这里我们会重点分析ExternalAppendOnlyMap。</p>
<p>ExternalAppendOnlyMap 作为内存缓冲数据的对象如下：</p>
<p> private var currentMap = new SizeTrackingAppendOnlyMap[K, C]<br>如果currentMap 对象向申请不到内存，就会触发spill动作。判定内存是否充足的逻辑和Shuffle Write 完全一致。</p>
<p>Combine做完之后，ExternalAppendOnlyMap 会返回一个Iterator，叫做ExternalIterator,这个Iterator背后的数据源是所有spill文件以及当前currentMap里的数据。</p>
<p>我们进去 ExternalIterator 看看，唯一的一个占用内存的对象是这个优先队列：</p>
<p>   private val mergeHeap = new mutable.PriorityQueue[StreamBuffer]<br>mergeHeap 里元素数量等于所有spill文件个数加一。StreamBuffer 的结构：</p>
<p> private class StreamBuffer(<br>                    val iterator: BufferedIterator[(K, C)],<br>                    val pairs: ArrayBuffer[(K, C)])<br>其中iterator 只是一个对象引用，pairs 应该保存的是iterator里的第一个元素(如果hash有冲突的话，则为多个)</p>
<p>所以mergeHeap 应该不占用什么内存。到这里我们看看应该占用多少内存。依然假设 CoreNum 为 C,则</p>
<p>  C <em> 32k + C  </em> mergeHeap  + C * SizeTrackingAppendOnlyMap<br>所以这一段占用内存较大的依然是 SizeTrackingAppendOnlyMap ，一样的，他的值也符合如下公式</p>
<p> C <em> SizeTrackingAppendOnlyMap &lt; ExecutorHeapMemeory </em> 0.2 * 0.8<br>ExternalAppendOnlyMap 的目的是做Combine,然后如果你还设置了Order,那么接着会启用 ExternalSorter 来完成排序。</p>
<p>经过上文对Shuffle Write的使用，相比大家也对ExternalSorter有一定的了解了，此时应该占用内存的地方最大不超过下面的这个值：</p>
<p> C <em> SizeTrackingAppendOnlyMap  + C </em> PartitionedAppendOnlyMap<br>不过即使如此，因为他们共享一个shuffleMemoryManager，则理论上只有这么大：</p>
<p> C <em> SizeTrackingAppendOnlyMap &lt;  ExecutorHeapMemeory </em> 0.2 * 0.8<br>分析到这里，我们可以做个总结：</p>
<p>Shuffle Read阶段如果内存不足，有两个阶段会落磁盘，分别是Combine 和 Sort 阶段。对应的都会spill小文件，并且产生读。<br>Shuffle Read 阶段如果开启了spill功能，则基本能保证内存控制在 ExecutorHeapMemeory <em> 0.2 </em> 0.8 之内。<br>后话<br>如果大家对Sort Shuffle 落磁盘文件这块感兴趣，还可以看看这篇文章 <a href="http://www.jianshu.com/p/2d837bf2dab6" target="_blank" rel="noopener">Spark Shuffle Write阶段磁盘文件分析</a><br>转载 <a href="http://www.jianshu.com/p/c83bb237caa8" target="_blank" rel="noopener">http://www.jianshu.com/p/c83bb237caa8</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/01/24/scala-rumen-biji/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/24/scala-rumen-biji/" itemprop="url">scala入门笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-24T19:09:23+08:00">
                2016-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scala/" itemprop="url" rel="index">
                    <span itemprop="name">scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Scala_u7B80_u4ECB"><a href="#Scala_u7B80_u4ECB" class="headerlink" title="Scala简介"></a>Scala简介</h3><p>Scala 是一门多范式的编程语言, 由Martin Odersky 于2001年基于Funnel的工作开始设计Scala并于2004年正式发布<br>Scala是一种纯面向对象的语言，每个值都是对象<br>Scala是一门多范式编程语言, 支持命令交互式, 函数式, 面向对象<br>编译型高性能语言(静态)<br>与Java无缝兼容, 可以使用任何Java库</p>
<h3 id="u4EE3_u7801_u98CE_u683C"><a href="#u4EE3_u7801_u98CE_u683C" class="headerlink" title="代码风格"></a>代码风格</h3><ol>
<li>函数和变量以小驼峰命名</li>
<li>类和特质以大驼峰命名</li>
<li>常量使用全大写命名</li>
<li>一般使用两格缩进</li>
<li>Scala大部分情况可以忽略语句末尾的分号<h3 id="Scala_u53D8_u91CF"><a href="#Scala_u53D8_u91CF" class="headerlink" title="Scala变量"></a>Scala变量</h3>Scala中尽量避免使用变量, 函数式编程的一个重要特性是不可变性(不可变变量没有副作用)<br>Scala是静态类型语言, 但是不需要显式的指明变量类型, Scala采用类型推断(Type Inference)<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义一个变量</span></span><br><span class="line"><span class="keyword">var</span> x = <span class="number">0</span></span><br><span class="line"><span class="comment">// 定义</span></span><br><span class="line"><span class="keyword">val</span> y = <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Scala_u57FA_u672C_u7C7B_u578B_u548C_u64CD_u4F5C"><a href="#Scala_u57FA_u672C_u7C7B_u578B_u548C_u64CD_u4F5C" class="headerlink" title="Scala基本类型和操作"></a>Scala基本类型和操作</h3><p>String和值类型Byte, Short, Int, Long, Float, Double, Char, Boolean</p>
<ul>
<li>Scala的操作符不是特殊的语言语法, 任何方法都可以是操作符</li>
<li>操作符分为前缀, 中缀, 后缀</li>
<li>Scala中所有操作符都是方法调用<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 前缀</span><br><span class="line">scala&gt; (<span class="number">2.0</span>).unary_-</span><br><span class="line">res1: <span class="type">Double</span> = <span class="number">-2.0</span></span><br><span class="line"># 中缀</span><br><span class="line">scala&gt; x indexOf 'o'</span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">4</span></span><br><span class="line"># 后缀</span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="string">"Hello, World"</span></span><br><span class="line">x: <span class="type">String</span> = <span class="type">Hello</span>, <span class="type">World</span></span><br><span class="line">scala&gt; x.toLowerCase</span><br><span class="line">res0: <span class="type">String</span> = hello, world</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>中缀操作符的两个操作数, 一个在左一个在右<br>前缀操作符方法名在操作符上加了unary_前缀(+, -, !, ~)<br>后缀操作符是不用点或括号调用的不带任何参数的方法<br>算术操作符: +, -, *, /, %<br>关系, 逻辑和位操作: &gt;, &lt;, &gt;=, &lt;=, ==, !=, &amp;&amp;, ||, &amp;, |, ^, ~(反码)<br>位移操作: &lt;&lt;, &gt;&gt;, &gt;&gt;&gt;(无符号右移)</p>
<h3 id="Scala_u51FD_u6570"><a href="#Scala_u51FD_u6570" class="headerlink" title="Scala函数"></a>Scala函数</h3><p>函数式语言的一个主要特征是, 函数是第一类结构<br>函数定义如下图:<br><img src="http://ww4.sinaimg.cn/large/ab508d3djw1eznwrn1zjcj20iv0d6taj.jpg" alt="scala function" title="scala 函数"><br>Unit 的结果类型指的是函数没有返回有用的值</p>
<h3 id="u51FD_u6570_u5F0F_u5BF9_u8C61"><a href="#u51FD_u6570_u5F0F_u5BF9_u8C61" class="headerlink" title="函数式对象"></a>函数式对象</h3><p>object和class的区别在于: object关键字创建一个单例对象<br>主构造器是类的唯一入口, 只有主构造器可以调用超类构造器<br>override关键字用于在重载父类的非抽象成员和成员函数<br>同一个类内函数名相同而参数类型和个数不同的函数重载不需要override<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span> (<span class="params">n: <span class="type">Int</span>, d: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">//precondition</span></span><br><span class="line">  require(d != <span class="number">0</span>)</span><br><span class="line">  <span class="comment">// 私有成员</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> g = gcd(n.abs, d.abs)</span><br><span class="line">  <span class="keyword">var</span> numer: <span class="type">Int</span> = n / g</span><br><span class="line">  <span class="keyword">var</span> denom: <span class="type">Int</span> = d / g</span><br><span class="line">  <span class="comment">// auxiliary constructor, 相当于python中__init__构造函数</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(n: <span class="type">Int</span>) = <span class="keyword">this</span>(n, <span class="number">1</span>)</span><br><span class="line">  <span class="comment">// 函数重载</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span> </span>= n + <span class="string">"/"</span> + d;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(other: <span class="type">Rational</span>): <span class="type">Rational</span> =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer * other.denom + other.numer * denom, denom * other.denom)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">-</span></span>(other: <span class="type">Rational</span>): <span class="type">Rational</span> =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer * other.denom - other.numer * denom, denom * other.denom)</span><br><span class="line">  <span class="comment">// 函数重载</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">-</span></span>(i: <span class="type">Int</span>): <span class="type">Rational</span> =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer - i * denom, denom)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">*</span></span>(other: <span class="type">Rational</span>): <span class="type">Rational</span> =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer * other.numer, denom * other.denom)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">lessThan</span></span>(other: <span class="type">Rational</span>): <span class="type">Boolean</span> =</span><br><span class="line">    <span class="keyword">this</span>.numer * other.denom &lt; other.numer * <span class="keyword">this</span>.denom</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(other: <span class="type">Rational</span>): <span class="type">Rational</span> =</span><br><span class="line">    <span class="keyword">if</span> (lessThan(other)) other <span class="keyword">else</span> <span class="keyword">this</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">gcd</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">    <span class="keyword">if</span> (b == <span class="number">0</span>) a <span class="keyword">else</span> gcd(b, a % b)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> x = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">var</span> y = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">5</span>, <span class="number">7</span>);</span><br><span class="line">println(x add y)</span><br><span class="line">println(x * y)</span><br><span class="line">println(x - <span class="number">1</span>)</span><br><span class="line"><span class="comment">// 隐式转换, 放在解释器方位内</span></span><br><span class="line"><span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">intToRational</span></span>(x: <span class="type">Int</span>) = <span class="keyword">new</span> <span class="type">Rational</span>(x)</span><br><span class="line">println(<span class="number">1</span> - x)</span><br></pre></td></tr></table></figure></p>
<h3 id="u7EE7_u627F_u548C_u591A_u6001"><a href="#u7EE7_u627F_u548C_u591A_u6001" class="headerlink" title="继承和多态"></a>继承和多态</h3><p>继承<br>多态和动态绑定特性<br>动态绑定的特性即父类指针可以指向子类对象, 通过父类指针调用成员方法时, 会查找实际所指向的对象, 然后调用对象的内的对应方法<br><img src="http://ww4.sinaimg.cn/large/ab508d3djw1ezyaprbvcmj20qo0ecmyq.jpg" alt="继承和多态"><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> el: <span class="type">Element</span> = <span class="keyword">new</span> <span class="type">ArrayElement</span>(<span class="type">Array</span>(<span class="string">"hello"</span>))</span><br><span class="line"><span class="keyword">val</span> e2: <span class="type">ArrayElement</span> = <span class="keyword">new</span> <span class="type">LineElement</span>(<span class="string">"hello"</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="u5185_u5EFA_u63A7_u5236_u7ED3_u6784"><a href="#u5185_u5EFA_u63A7_u5236_u7ED3_u6784" class="headerlink" title="内建控制结构"></a>内建控制结构</h3><p>表示式会产生一个值<br>Scala中if是能返回值的表达式, Scala中没有三元操作符, 但通过if (condition) var1 else var2 可以实现三元操作符的功能<br>while和do-while被称为循环, 不产生有意义的结果<br>Scala中for语句非常强大, for {子句} yield {循环体}<br>match表达式可以产生值, match远强大与其他语言中的switch, 而且不需要显示的声明break<br>变量范围: 大括号引入了一个新的范围, 内部变量会遮盖同名的外部变量<br>占位符语法<br>函数文本(匿名函数, 类似于python中的lamda)<br><img src="http://ww3.sinaimg.cn/large/ab508d3djw1eznwvjaswlj20dv05bgmc.jpg" alt="scala函数文本语法"><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> filename = <span class="keyword">if</span> (!args.isEmpty) args(<span class="number">0</span>) <span class="keyword">else</span> <span class="string">"default.txt"</span></span><br><span class="line"><span class="keyword">var</span> filesList = (<span class="keyword">new</span> <span class="type">File</span>(<span class="string">"."</span>)).listFiles</span><br><span class="line"><span class="comment">// i &lt;- 1 to 4(包含4), i &lt;- 1 until 4 (不包含4)</span></span><br><span class="line"><span class="keyword">for</span> (file &lt;- filesList</span><br><span class="line">     <span class="keyword">if</span> file.isFile;</span><br><span class="line">     <span class="keyword">if</span> file.getName.endsWith(<span class="string">".scala"</span>))  <span class="comment">// 过滤器使用分号隔开</span></span><br><span class="line">    println(file)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">var</span> firstArg = <span class="keyword">if</span>(args.length &gt; <span class="number">0</span>) args(<span class="number">0</span>) <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line"><span class="comment">// 任何种类的常量和其他都可以作为case</span></span><br><span class="line">firstArg <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"text"</span> =&gt; println(<span class="string">"text"</span>)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; println(<span class="string">"default"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 匿名函数的写法(lambda)</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> someNumbers = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">scala&gt; someNumbers.filter(x =&gt; x % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line"><span class="comment">// 占位符语法</span></span><br><span class="line">scala&gt; someNumbers.filter(_ % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line"><span class="comment">// 偏函数 partial funciton</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>, c: <span class="type">Int</span>) = a + b + c</span><br><span class="line">scala&gt; <span class="keyword">val</span> a = sum(<span class="number">1</span>, _: <span class="type">Int</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt; a(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// 变长参数(Array[String])</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">echo</span></span>(args: <span class="type">String</span>*) = <span class="keyword">for</span>(arg &lt;- args) println(arg)</span><br><span class="line">scala&gt; echo(<span class="string">"one"</span>)</span><br><span class="line">scala&gt; echo(<span class="string">"one"</span>, <span class="string">"two"</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultConstructor</span> (<span class="params"> name:<span class="type">String</span> , age:<span class="type">Int</span></span>)</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(name:<span class="type">String</span>)&#123;</span><br><span class="line">    <span class="comment">/*自定义构造器，必需首先调用默认构造器*/</span></span><br><span class="line">    <span class="keyword">this</span>(name , <span class="number">24</span>) ; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">show</span></span>()&#123;</span><br><span class="line">    println( name + <span class="string">"--&gt;"</span> + age ) ;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>柯里化(carry)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 普通函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(x: <span class="type">Int</span>, y: <span class="type">Int</span>) = x + y</span><br><span class="line"><span class="comment">// 柯里化函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(x: <span class="type">Int</span>)(y: <span class="type">Int</span>) = x + y</span><br><span class="line"><span class="comment">// 实际执行</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(x: <span class="type">Int</span>) = (y: <span class="type">Int</span>) =&gt; x + y</span><br></pre></td></tr></table></figure></p>
<h3 id="u7279_u8D28_28trait_29"><a href="#u7279_u8D28_28trait_29" class="headerlink" title="特质(trait)"></a>特质(trait)</h3><p>特质就像带有具体方法的java接口<br>特质和抽象类的区别: 抽象类主要用于有明确的父子继承关系的类树, 而特质可以用于任何类<br>特质定义使用trait关键字<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Person</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail</span></span>() &#123;</span><br><span class="line">        println(<span class="string">"I'm angry!"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 使用extends或with混入特质, 从特质继承的方法可以像从超类继承的方法使用</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> <span class="keyword">with</span> <span class="title">Boy</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="u6570_u636E_u7ED3_u6784"><a href="#u6570_u636E_u7ED3_u6784" class="headerlink" title="数据结构"></a>数据结构</h3><p>Python中常用list, tuple, set, dict<br>Scala对应的数据结构为List, Tuple[X], Set, Map(HashMap)<br>Scala中默认为不可变对象, 操作会生成一个新的对象</p>
<h3 id="u5305"><a href="#u5305" class="headerlink" title="包"></a>包</h3><p>Scala采用java平台的包机制<br>使用import来进行引用<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zhihu.antispam</span><br></pre></td></tr></table></figure></p>
<h3 id="u53C2_u8003_u94FE_u63A5"><a href="#u53C2_u8003_u94FE_u63A5" class="headerlink" title="参考链接"></a>参考链接</h3><p><a href="http://stackoverflow.com/questions/1755345/difference-between-object-and-class-in-scala" target="_blank" rel="noopener">Difference between object and class in Scala</a><br><a href="https://www.zybuluo.com/Great-Chinese/note/254972" target="_blank" rel="noopener">scala 入门</a><br><a href="http://colobu.com/2016/01/04/Scala-magic-functions/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="noopener">Scala 魔法函数</a><br><a href="http://blog.yunglinho.com/blog/2012/04/22/dependency-injection-in-scala/" target="_blank" rel="noopener">Dependency Injection in Scala</a><br><a href="http://www.hawstein.com/posts/databricks-scala-guide.html" target="_blank" rel="noopener">Databricks Scala 编程风格指南</a><br><a href="http://stackoverflow.com/questions/8000903/what-are-all-the-uses-of-an-underscore-in-scala" target="_blank" rel="noopener">What are all the uses of an underscore in Scala?</a></p>
<p>转载 <a href="http://andrewliu.in/2016/01/16/Scala%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/" target="_blank" rel="noopener">http://andrewliu.in/2016/01/16/Scala%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/01/24/spark-convert-text-parquet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/24/spark-convert-text-parquet/" itemprop="url">将 Spark 中的文本转换为 Parquet 以提升性能</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-24T18:46:44+08:00">
                2016-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>列式存储布局（比如 Parquet）可以加速查询，因为它只检查所有需要的列并对它们的值执行计算，因此只读取一个数据文件或表的小部分数据。Parquet 还支持灵活的压缩选项，因此可以显著减少磁盘上的存储。<br>如果您在 HDFS 上拥有基于文本的数据文件或表，而且正在使用 Spark SQL 对它们执行查询，那么强烈推荐将文本数据文件转换为 Parquet 数据文件，以实现性能和存储收益。当然，转换需要时间，但查询性能的提升在某些情况下可能达到 30 倍或更高，存储的节省可高达 75%！<br>已有文章介绍使用 Parquet 存储为 BigSQL、Hive 和 Impala 带来类似的性能收益，本文将介绍如何编写一个简单的 Scala 应用程序，将现有的基于文本的数据文件或表转换为 Parquet 数据文件，还将展示给 Spark SQL 带来的实际存储节省和查询性能提升。</p>
<h3 id="u8BA9_u6211_u4EEC_u8F6C_u6362_u4E3A_Parquet__u5427_uFF01"><a href="#u8BA9_u6211_u4EEC_u8F6C_u6362_u4E3A_Parquet__u5427_uFF01" class="headerlink" title="让我们转换为 Parquet 吧！"></a>让我们转换为 Parquet 吧！</h3><p>Spark SQL 提供了对读取和写入 Parquet 文件的支持，能够自动保留原始数据的模式。Parquet 模式通过 Data Frame API，使数据文件对 Spark SQL 应用程序 “不言自明”。当然，Spark SQL 还支持读取已存储为 Parquet 的现有 Hive 表，但您需要配置 Spark，以便使用 Hive 的元存储来加载所有信息。在我们的示例中，不涉及 Hive 元存储。<br>以下 Scala 代码示例将读取一个基于文本的 CSV 表，并将它写入 Parquet 表：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span></span>(sqlContext: <span class="type">SQLContext</span>, filename: <span class="type">String</span>, schema: <span class="type">StructType</span>, tablename: <span class="type">String</span>) &#123;</span><br><span class="line">     <span class="comment">// import text-based table first into a data frame</span></span><br><span class="line">     <span class="keyword">val</span> df = sqlContext.read.format(<span class="string">"com.databricks.spark.csv"</span>).</span><br><span class="line">       schema(schema).option(<span class="string">"delimiter"</span>, <span class="string">"|"</span>).load(filename)</span><br><span class="line">     <span class="comment">// now simply write to a parquet file</span></span><br><span class="line">     df.write.parquet(<span class="string">"/user/spark/data/parquet/"</span>+tablename)</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// usage exampe -- a tpc-ds table called catalog_page</span></span><br><span class="line"> schema= <span class="type">StructType</span>(<span class="type">Array</span>(</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_sk"</span>,        <span class="type">IntegerType</span>,<span class="literal">false</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_id"</span>,        <span class="type">StringType</span>,<span class="literal">false</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_start_date_sk"</span>,          <span class="type">IntegerType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_end_date_sk"</span>,            <span class="type">IntegerType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_department"</span>,             <span class="type">StringType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_number"</span>,         <span class="type">LongType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_catalog_page_number"</span>,    <span class="type">LongType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_description"</span>,            <span class="type">StringType</span>,<span class="literal">true</span>),</span><br><span class="line">         <span class="type">StructField</span>(<span class="string">"cp_type"</span>,                   <span class="type">StringType</span>,<span class="literal">true</span>)))</span><br><span class="line"> convert(sqlContext,</span><br><span class="line">         hadoopdsPath+<span class="string">"/catalog_page/*"</span>,</span><br><span class="line">         schema,</span><br><span class="line">         <span class="string">"catalog_page"</span>)</span><br></pre></td></tr></table></figure></p>
<p>上面的代码将会读取 hadoopdsPath+”/catalog_page/* 中基于文本的 CSV 文件，并将转换的 Parquet 文件保存在 /user/spark/data/parquet/ 下。此外，转换的 Parquet 文件会在 gzip 中自动压缩，因为 Spark 变量 spark.sql.parquet.compression.codec 已在默认情况下设置为 gzip。您还可以将压缩编解码器设置为 uncompressed、snappy 或 lzo。</p>
<h3 id="u8F6C_u6362_1_TB__u6570_u636E_u5C06_u82B1_u8D39_u591A_u957F_u65F6_u95F4_uFF1F"><a href="#u8F6C_u6362_1_TB__u6570_u636E_u5C06_u82B1_u8D39_u591A_u957F_u65F6_u95F4_uFF1F" class="headerlink" title="转换 1 TB 数据将花费多长时间？"></a>转换 1 TB 数据将花费多长时间？</h3><p>50 分钟，在一个 6 数据节点的 Spark v1.5.1 集群上可达到约 20 GB/分的吞吐量。使用的总内存约为 500GB。HDFS 上最终的 Parquet 文件的格式为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/user/spark/data/parquet/catalog_page/part-r-00000-9ff58e65-0674-440a-883d-256370f33c66.gz.parquet</span><br><span class="line">/user/spark/data/parquet/catalog_page/part-r-00001-9ff58e65-0674-440a-883d-256370f33c66.gz.parquet</span><br></pre></td></tr></table></figure></p>
<h3 id="u5B58_u50A8_u8282_u7701"><a href="#u5B58_u50A8_u8282_u7701" class="headerlink" title="存储节省"></a>存储节省</h3><p>以下 Linux 输出显示了 TEXT 和 PARQUET 在 HDFS 上的大小比较：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -du -h -s /user/spark/hadoopds1000g</span><br><span class="line">    897.9 G  /user/spark/hadoopds1000g</span><br><span class="line">    % hadoop fs -du -h -s /user/spark/data/parquet</span><br><span class="line">    231.4 G  /user/spark/data/parquet</span><br></pre></td></tr></table></figure></p>
<p>1 TB 数据的存储节省了将近 75%！</p>
<h3 id="u67E5_u8BE2_u6027_u80FD_u63D0_u5347"><a href="#u67E5_u8BE2_u6027_u80FD_u63D0_u5347" class="headerlink" title="查询性能提升"></a>查询性能提升</h3><p>Parquet 文件是自描述性的，所以保留了模式。要将 Parquet 文件加载到 DataFrame 中并将它注册为一个 temp 表，可执行以下操作：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = sqlContext.read.parquet(filename)</span><br><span class="line">      df.show</span><br><span class="line">      df.registerTempTable(tablename)</span><br></pre></td></tr></table></figure></p>
<p>要对比性能，然后可以分别对 TEXT 和 PARQUET 表运行以下查询（假设所有其他 tpc-ds 表也都已转换为 Parquet）。您可以利用 spark-sql-perf 测试工具包来执行查询测试。举例而言，现在来看看 TPC-DS 基准测试中的查询 #76，<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">("q76", """</span><br><span class="line">            | <span class="keyword">SELECT</span></span><br><span class="line">            |    channel, col_name, d_year, d_qoy, i_category, <span class="keyword">COUNT</span>(*) sales_cnt,</span><br><span class="line">            |    <span class="keyword">SUM</span>(ext_sales_price) sales_amt</span><br><span class="line">            | <span class="keyword">FROM</span>(</span><br><span class="line">            |    <span class="keyword">SELECT</span></span><br><span class="line">            |        <span class="string">'store'</span> <span class="keyword">as</span> channel, ss_store_sk col_name, d_year, d_qoy, i_category,</span><br><span class="line">            |        ss_ext_sales_price ext_sales_price</span><br><span class="line">            |    <span class="keyword">FROM</span> store_sales, item, date_dim</span><br><span class="line">            |    <span class="keyword">WHERE</span> ss_store_sk <span class="keyword">IS</span> <span class="literal">NULL</span></span><br><span class="line">            |      <span class="keyword">AND</span> ss_sold_date_sk=d_date_sk</span><br><span class="line">            |      <span class="keyword">AND</span> ss_item_sk=i_item_sk</span><br><span class="line">            |    <span class="keyword">UNION</span> ALL</span><br><span class="line">            |    <span class="keyword">SELECT</span></span><br><span class="line">            |        <span class="string">'web'</span> <span class="keyword">as</span> channel, ws_ship_customer_sk col_name, d_year, d_qoy, i_category,</span><br><span class="line">            |        ws_ext_sales_price ext_sales_price</span><br><span class="line">            |    <span class="keyword">FROM</span> web_sales, item, date_dim</span><br><span class="line">            |    <span class="keyword">WHERE</span> ws_ship_customer_sk <span class="keyword">IS</span> <span class="literal">NULL</span></span><br><span class="line">            |      <span class="keyword">AND</span> ws_sold_date_sk=d_date_sk</span><br><span class="line">            |      <span class="keyword">AND</span> ws_item_sk=i_item_sk</span><br><span class="line">            |    <span class="keyword">UNION</span> ALL</span><br><span class="line">            |    <span class="keyword">SELECT</span></span><br><span class="line">            |        <span class="string">'catalog'</span> <span class="keyword">as</span> channel, cs_ship_addr_sk col_name, d_year, d_qoy, i_category,</span><br><span class="line">            |        cs_ext_sales_price ext_sales_price</span><br><span class="line">            |    <span class="keyword">FROM</span> catalog_sales, item, date_dim</span><br><span class="line">            |    <span class="keyword">WHERE</span> cs_ship_addr_sk <span class="keyword">IS</span> <span class="literal">NULL</span></span><br><span class="line">            |      <span class="keyword">AND</span> cs_sold_date_sk=d_date_sk</span><br><span class="line">            |      <span class="keyword">AND</span> cs_item_sk=i_item_sk) foo</span><br><span class="line">            | <span class="keyword">GROUP</span> <span class="keyword">BY</span> channel, col_name, d_year, d_qoy, i_category</span><br><span class="line">            | <span class="keyword">ORDER</span> <span class="keyword">BY</span> channel, col_name, d_year, d_qoy, i_category</span><br><span class="line">            | <span class="keyword">limit</span> <span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<p>查询时间如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TIME               TEXT     PARQUET</span><br><span class="line">Query time (sec)    698          21</span><br></pre></td></tr></table></figure></p>
<p>参考资料<br><a href="https://developer.ibm.com/hadoop/blog/2015/12/03/parquet-for-spark-sql/" target="_blank" rel="noopener">英文原文。</a><br>在 <a href="http://www.ibm.com/developerworks/cn/bigdata/" target="_blank" rel="noopener">developerWorks 大数据和分析专区</a>，了解关于大数据的更多信息，获取技术文档、how-to 文章、培训、下载、产品信息以及其他资源。<br>加入 <a href="http://www.ibm.com/developerworks/cn/community/" target="_blank" rel="noopener">developerWorks 中文社区</a>，查看开发人员推动的博客、论坛、组和维基，并与其他 developerWorks 用户交流。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://blog.djstudy.net/2016/01/24/spark-ha/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="东杰">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东杰书屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/24/spark-ha/" itemprop="url">Spark Standalone模式HA环境搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-24T16:10:30+08:00">
                2016-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Spark Standalone模式常见的HA部署方式有两种：基于文件系统的HA和基于ZK的HA<br>本篇只介绍基于ZK的HA环境搭建：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ SPARK_HOME/conf/spark-env.sh</span><br></pre></td></tr></table></figure></p>
<p>添加SPARK_DAEMON_JAVA_OPTS的配置信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop000:2181,hadoop001:2181,hadoop002:2181 -Dspark.deploy.zookeeper.dir=/spark"</span></span><br></pre></td></tr></table></figure></p>
<h3 id="u914D_u7F6E_u53C2_u6570_u8BF4_u660E_uFF1A"><a href="#u914D_u7F6E_u53C2_u6570_u8BF4_u660E_uFF1A" class="headerlink" title="配置参数说明："></a>配置参数说明：</h3><p>spark.deploy.recoveryMode: 设置恢复模式为zk，默认为NONE<br>spark.deploy.zookeeper.url: 设置ZK集群的url，形如：192.168.1.100:2181,192.168.1.101:2181<br>spark.deploy.zookeeper.dir: 设置zk保存恢复状态的路径，默认为spark<br>实现HA的原理：利用ZK的Leader Election机制，选择一个Active状态的Master，其余的Master均为Standby状态；当Active状态的Master死掉后，通过ZK选举一个Standby状态的Master为Active状态。</p>
<h3 id="u6D4B_u8BD5_u6B65_u9AA4_uFF1A"><a href="#u6D4B_u8BD5_u6B65_u9AA4_uFF1A" class="headerlink" title="测试步骤："></a>测试步骤：</h3><p>启动standalone集群后，在各个Standby节点上启动start-master.sh，jps观察是否已经正确启动Master进程；<br>将Active状态的Master kill掉，观察8080端口对应的页面，发现已经从Standby状态中选举出一个当作Active状态。<br>采用ZK后由于会有多个Master，在提交任务时不知道哪个为Active状态的Master，可以采用如下的方式提交：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark-shell –master spark://hadoop000:7077,hadoop001:7077,hadoop002:7077 –executor-memory 2g –total-executor-cores 1</span><br><span class="line">详细信息参见官方文档：http://spark.apache.org/docs/latest/spark-standalone.html<span class="comment">#standby-masters-with-zookeeper</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">东杰</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hivefans" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://example.com/" title="Title" target="_blank">Title</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">东杰</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
